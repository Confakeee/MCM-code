{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16afe876",
   "metadata": {},
   "source": [
    "1st problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eac7bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from scipy import stats, optimize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# ==================== 1. ENHANCED DATA PROCESSING ====================\n",
    "\n",
    "class EnhancedDataProcessor:\n",
    "    \"\"\"Enhanced data processor for all 34 seasons\"\"\"\n",
    "    \n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.data = None\n",
    "        self.season_rules = {}\n",
    "        self.all_seasons_data = {}\n",
    "        \n",
    "    def load_and_clean_data(self):\n",
    "        \"\"\"Load and clean data from Excel or CSV\"\"\"\n",
    "        try:\n",
    "            if self.filepath.endswith(('.xlsx', '.xls')):\n",
    "                self.data = pd.read_excel(self.filepath)\n",
    "            else:\n",
    "                self.data = pd.read_csv(self.filepath)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {e}\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"‚úì Original data loaded: {len(self.data)} rows, {len(self.data.columns)} columns\")\n",
    "        \n",
    "        # Check and handle duplicate data\n",
    "        original_len = len(self.data)\n",
    "        \n",
    "        # Create unique identifier: season + celebrity_name\n",
    "        self.data['unique_id'] = self.data['season'].astype(str) + '_' + self.data['celebrity_name'].astype(str)\n",
    "        \n",
    "        # Find duplicate records\n",
    "        duplicates = self.data.duplicated(subset=['season', 'celebrity_name'], keep='first')\n",
    "        if duplicates.any():\n",
    "            print(f\"‚ö† Found {duplicates.sum()} duplicate records (same season and celebrity)\")\n",
    "            print(\"  Removing duplicates...\")\n",
    "            \n",
    "            # Show duplicate examples\n",
    "            dup_examples = self.data[duplicates][['season', 'celebrity_name']].head()\n",
    "            print(f\"  Example duplicates:\\n{dup_examples}\")\n",
    "            \n",
    "            # Remove duplicates, keep first record\n",
    "            self.data = self.data.drop_duplicates(subset=['season', 'celebrity_name'], keep='first')\n",
    "            print(f\"‚úì Removed {original_len - len(self.data)} duplicate rows\")\n",
    "        \n",
    "        print(f\"‚úì Cleaned data: {len(self.data)} rows\")\n",
    "        print(f\"‚úì Seasons found: {sorted(self.data['season'].unique())}\")\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "    def determine_season_rules_enhanced(self):\n",
    "        \"\"\"Determine voting rule for each season with enhanced detection\"\"\"\n",
    "        # According to problem description:\n",
    "        # Seasons 1-2: rank method\n",
    "        # Seasons 3-27: percentage method  \n",
    "        # Seasons 28-34: rank method\n",
    "        for season in self.data['season'].unique():\n",
    "            if season <= 2:\n",
    "                self.season_rules[season] = 'rank'\n",
    "            elif 3 <= season <= 27:\n",
    "                self.season_rules[season] = 'percentage'\n",
    "            else:  # season >= 28\n",
    "                self.season_rules[season] = 'rank'\n",
    "        \n",
    "        print(f\"\\nSeason rules determined for all {len(self.season_rules)} seasons:\")\n",
    "        \n",
    "        # Print summary\n",
    "        rank_seasons = [s for s, r in self.season_rules.items() if r == 'rank']\n",
    "        percentage_seasons = [s for s, r in self.season_rules.items() if r == 'percentage']\n",
    "        \n",
    "        print(f\"  Rank method seasons: {len(rank_seasons)} (1-2, 28-34)\")\n",
    "        print(f\"  Percentage method seasons: {len(percentage_seasons)} (3-27)\")\n",
    "        \n",
    "        return self.season_rules\n",
    "    \n",
    "    def prepare_all_seasons_data(self):\n",
    "        \"\"\"Prepare data for all 34 seasons\"\"\"\n",
    "        print(\"\\nPreparing data for all seasons...\")\n",
    "        \n",
    "        all_seasons = sorted(self.data['season'].unique())\n",
    "        total_seasons = len(all_seasons)\n",
    "        \n",
    "        for idx, season_num in enumerate(all_seasons, 1):\n",
    "            print(f\"  Season {season_num} ({idx}/{total_seasons})...\")\n",
    "            \n",
    "            season_data = self._prepare_single_season(season_num)\n",
    "            if season_data is not None:\n",
    "                self.all_seasons_data[season_num] = season_data\n",
    "        \n",
    "        print(f\"\\n‚úì Successfully prepared data for {len(self.all_seasons_data)} seasons\")\n",
    "        return self.all_seasons_data\n",
    "    \n",
    "    def _prepare_single_season(self, season_num):\n",
    "        \"\"\"Prepare data for a single season\"\"\"\n",
    "        season_data = self.data[self.data['season'] == season_num].copy()\n",
    "        season_data = season_data.reset_index(drop=True)\n",
    "        \n",
    "        if len(season_data) == 0:\n",
    "            return None\n",
    "        \n",
    "        # Determine max weeks\n",
    "        judge_cols = [col for col in season_data.columns \n",
    "                     if 'week' in str(col).lower() and 'judge' in str(col).lower()]\n",
    "        \n",
    "        if not judge_cols:\n",
    "            return None\n",
    "        \n",
    "        # Extract week numbers\n",
    "        week_nums = []\n",
    "        for col in judge_cols:\n",
    "            match = re.search(r'week(\\d+)_', str(col).lower())\n",
    "            if match:\n",
    "                week_nums.append(int(match.group(1)))\n",
    "        \n",
    "        if not week_nums:\n",
    "            return None\n",
    "            \n",
    "        max_week = max(week_nums)\n",
    "        \n",
    "        # Prepare features\n",
    "        features = self._extract_features_enhanced(season_data)\n",
    "        \n",
    "        # Prepare judge data\n",
    "        judge_data = self._extract_judge_data_enhanced(season_data, max_week)\n",
    "        \n",
    "        # Prepare elimination data\n",
    "        elimination_data = self._extract_elimination_data_enhanced(season_data, judge_data['active_mask'], max_week)\n",
    "        \n",
    "        # Determine rule type\n",
    "        rule_type = self.season_rules.get(season_num, 'percentage')\n",
    "        \n",
    "        # Store contestant names and IDs for later reference\n",
    "        contestant_info = []\n",
    "        for idx, row in season_data.iterrows():\n",
    "            contestant_info.append({\n",
    "                'index': idx,\n",
    "                'name': row['celebrity_name'] if 'celebrity_name' in row else f'Contestant_{idx}',\n",
    "                'original_index': row.name if 'name' in row else idx\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'season_num': season_num,\n",
    "            'original_data': season_data,\n",
    "            'features': features,\n",
    "            'judge_data': judge_data,\n",
    "            'elimination_data': elimination_data,\n",
    "            'max_week': max_week,\n",
    "            'rule_type': rule_type,\n",
    "            'n_contestants': len(season_data),\n",
    "            'contestant_info': contestant_info,\n",
    "            'season_data_indices': season_data.index.tolist()  # Save original indices\n",
    "        }\n",
    "    \n",
    "    def _extract_features_enhanced(self, season_data):\n",
    "        \"\"\"Extract enhanced features for fan vote prediction\"\"\"\n",
    "        features_list = []\n",
    "        feature_names = []\n",
    "        \n",
    "        # 1. Age feature (standardized)\n",
    "        if 'celebrity_age_during_season' in season_data.columns:\n",
    "            age = season_data['celebrity_age_during_season'].values\n",
    "            age = np.nan_to_num(age, nan=np.nanmean(age) if not np.all(np.isnan(age)) else 30)\n",
    "            if np.std(age) > 0:\n",
    "                age = (age - np.mean(age)) / np.std(age)\n",
    "            features_list.append(age.reshape(-1, 1))\n",
    "            feature_names.append('age_std')\n",
    "        \n",
    "        # 2. USA flag (binary)\n",
    "        country_col = None\n",
    "        for col in ['celebrity_homecountry/region', 'celebrity_homecountry', 'country']:\n",
    "            if col in season_data.columns:\n",
    "                country_col = col\n",
    "                break\n",
    "        \n",
    "        if country_col:\n",
    "            is_usa = season_data[country_col].astype(str).str.contains(\n",
    "                'United States|USA|U.S.|America', case=False, na=False)\n",
    "            features_list.append(is_usa.astype(float).values.reshape(-1, 1))\n",
    "            feature_names.append('is_usa')\n",
    "        \n",
    "        # 3. Previous performance (judge scores history)\n",
    "        judge_score_cols = [col for col in season_data.columns if 'judge' in str(col).lower() and 'score' in str(col).lower()]\n",
    "        if judge_score_cols:\n",
    "            judge_scores = season_data[judge_score_cols].values\n",
    "            mean_judge_scores = np.nanmean(np.where(judge_scores > 0, judge_scores, np.nan), axis=1)\n",
    "            mean_judge_scores = np.nan_to_num(mean_judge_scores, nan=np.nanmean(mean_judge_scores) if not np.all(np.isnan(mean_judge_scores)) else 7)\n",
    "            if np.std(mean_judge_scores) > 0:\n",
    "                mean_judge_scores = (mean_judge_scores - np.mean(mean_judge_scores)) / np.std(mean_judge_scores)\n",
    "            features_list.append(mean_judge_scores.reshape(-1, 1))\n",
    "            feature_names.append('avg_judge_score')\n",
    "        \n",
    "        # 4. Partner experience\n",
    "        if 'ballroom_partner' in season_data.columns:\n",
    "            partner_counts = season_data['ballroom_partner'].value_counts()\n",
    "            experienced_partners = partner_counts[partner_counts > 2].index.tolist()\n",
    "            \n",
    "            for partner in experienced_partners[:3]:\n",
    "                if pd.notna(partner):\n",
    "                    partner_feature = (season_data['ballroom_partner'] == partner).astype(float).values\n",
    "                    features_list.append(partner_feature.reshape(-1, 1))\n",
    "                    feature_names.append(f'partner_{partner[:10].replace(\" \", \"_\")}')\n",
    "        \n",
    "        # 5. Industry popularity\n",
    "        if 'celebrity_industry' in season_data.columns:\n",
    "            industry_weights = {\n",
    "                'Actor': 1.0, 'Singer': 0.9, 'Athlete': 0.8, 'Model': 0.7,\n",
    "                'Reality TV Star': 0.6, 'Political Figure': 0.5, 'TV Personality': 0.7,\n",
    "                'Comedian': 0.7, 'Musician': 0.9, 'Dancer': 0.6, 'Actor/Singer': 0.95,\n",
    "                'Singer/Actor': 0.95, 'Athlete/Model': 0.75\n",
    "            }\n",
    "            \n",
    "            industry_feature = np.zeros(len(season_data))\n",
    "            for idx, industry in enumerate(season_data['celebrity_industry']):\n",
    "                if pd.isna(industry):\n",
    "                    industry_feature[idx] = 0.5\n",
    "                else:\n",
    "                    industry_str = str(industry).strip()\n",
    "                    industry_feature[idx] = industry_weights.get(industry_str, 0.5)\n",
    "            \n",
    "            features_list.append(industry_feature.reshape(-1, 1))\n",
    "            feature_names.append('industry_popularity')\n",
    "        \n",
    "        # 6. Add intercept term\n",
    "        features_list.append(np.ones((len(season_data), 1)))\n",
    "        feature_names.append('intercept')\n",
    "        \n",
    "        # Combine all features\n",
    "        if features_list:\n",
    "            X = np.hstack(features_list)\n",
    "        else:\n",
    "            X = np.ones((len(season_data), 1))\n",
    "            feature_names = ['intercept']\n",
    "        \n",
    "        return {\n",
    "            'matrix': X,\n",
    "            'names': feature_names,\n",
    "            'n_features': X.shape[1]\n",
    "        }\n",
    "    \n",
    "    def _extract_judge_data_enhanced(self, season_data, max_week):\n",
    "        \"\"\"Extract enhanced judge data\"\"\"\n",
    "        n_contestants = len(season_data)\n",
    "        \n",
    "        judge_scores = np.zeros((n_contestants, max_week))\n",
    "        judge_percentages = np.zeros((n_contestants, max_week))\n",
    "        judge_ranks = np.zeros((n_contestants, max_week))\n",
    "        active_mask = np.zeros((n_contestants, max_week), dtype=bool)\n",
    "        \n",
    "        for week in range(1, max_week + 1):\n",
    "            # Find judge score columns\n",
    "            judge_cols = []\n",
    "            for i in range(1, 5):\n",
    "                for pattern in [f'week{week}_judge{i}_score', f'Week{week}_Judge{i}_Score']:\n",
    "                    if pattern in season_data.columns:\n",
    "                        judge_cols.append(pattern)\n",
    "                        break\n",
    "            \n",
    "            if judge_cols:\n",
    "                scores = season_data[judge_cols].mean(axis=1).values\n",
    "                judge_scores[:, week-1] = scores\n",
    "                active_mask[:, week-1] = scores > 0\n",
    "                \n",
    "                # Calculate judge percentages\n",
    "                active_idx = np.where(active_mask[:, week-1])[0]\n",
    "                if len(active_idx) > 0:\n",
    "                    active_scores = scores[active_idx]\n",
    "                    if np.sum(active_scores) > 0:\n",
    "                        percentages = active_scores / np.sum(active_scores)\n",
    "                        judge_percentages[active_idx, week-1] = percentages\n",
    "            \n",
    "            # Get judge ranks\n",
    "            for pattern in [f'Week{week}_Rank', f'week{week}_rank']:\n",
    "                if pattern in season_data.columns:\n",
    "                    ranks = season_data[pattern].values\n",
    "                    ranks = np.nan_to_num(ranks, nan=np.max(ranks[~np.isnan(ranks)]) + 1 \n",
    "                                          if np.any(~np.isnan(ranks)) else len(season_data))\n",
    "                    judge_ranks[:, week-1] = ranks\n",
    "                    break\n",
    "        \n",
    "        return {\n",
    "            'scores': judge_scores,\n",
    "            'percentages': judge_percentages,\n",
    "            'ranks': judge_ranks,\n",
    "            'active_mask': active_mask\n",
    "        }\n",
    "    \n",
    "    def _extract_elimination_data_enhanced(self, season_data, active_mask, max_week):\n",
    "        \"\"\"Enhanced elimination data extraction\"\"\"\n",
    "        n_contestants = len(season_data)\n",
    "        eliminated_idx = [None] * max_week\n",
    "        \n",
    "        for week in range(1, max_week):\n",
    "            current_active = active_mask[:, week-1]\n",
    "            \n",
    "            if week < max_week:\n",
    "                next_active = active_mask[:, week]\n",
    "                eliminated_candidates = np.where(current_active & ~next_active)[0]\n",
    "            else:\n",
    "                eliminated_candidates = np.array([], dtype=int)\n",
    "            \n",
    "            if len(eliminated_candidates) == 1:\n",
    "                eliminated_idx[week-1] = eliminated_candidates[0]\n",
    "            elif len(eliminated_candidates) > 1:\n",
    "                # Check results column first\n",
    "                if 'results' in season_data.columns:\n",
    "                    for candidate in eliminated_candidates:\n",
    "                        result = str(season_data.iloc[candidate]['results'])\n",
    "                        if f'Eliminated Week {week}' in result or f'eliminated week {week}' in result.lower():\n",
    "                            eliminated_idx[week-1] = candidate\n",
    "                            break\n",
    "                \n",
    "                # If not found, use placement or other indicators\n",
    "                if eliminated_idx[week-1] is None and 'placement' in season_data.columns:\n",
    "                    # Higher placement number means eliminated earlier\n",
    "                    placements = season_data.loc[eliminated_candidates, 'placement'].values\n",
    "                    if np.any(~np.isnan(placements)):\n",
    "                        max_placement = np.nanmax(placements)\n",
    "                        eliminated_idx[week-1] = eliminated_candidates[\n",
    "                            np.where(placements == max_placement)[0][0]\n",
    "                        ]\n",
    "                \n",
    "                # Last resort: first candidate\n",
    "                if eliminated_idx[week-1] is None:\n",
    "                    eliminated_idx[week-1] = eliminated_candidates[0]\n",
    "        \n",
    "        return eliminated_idx\n",
    "\n",
    "# ==================== 2. IMPROVED OPTIMIZATION MODEL ====================\n",
    "\n",
    "class ImprovedOptimizationModel:\n",
    "    \"\"\"\n",
    "    Improved optimization model for fan vote estimation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, total_votes=10000000):\n",
    "        self.all_predictions = {}\n",
    "        self.total_votes = total_votes\n",
    "        \n",
    "    def solve_all_seasons(self, all_seasons_data):\n",
    "        \"\"\"Solve for all seasons\"\"\"\n",
    "        print(\"\\nSolving optimization for all seasons...\")\n",
    "        \n",
    "        for season_num, season_data in all_seasons_data.items():\n",
    "            print(f\"  Season {season_num}...\", end=\" \", flush=True)\n",
    "            \n",
    "            fan_pct = self._solve_single_season_optimized(season_data)\n",
    "            self.all_predictions[season_num] = fan_pct\n",
    "            \n",
    "            consistency = self._calculate_consistency(fan_pct, season_data)\n",
    "            print(f\"Consistency: {consistency:.1%}\")\n",
    "        \n",
    "        print(f\"\\n‚úì Completed predictions for {len(self.all_predictions)} seasons\")\n",
    "        return self.all_predictions\n",
    "    \n",
    "    def _solve_single_season_optimized(self, season_data):\n",
    "        \"\"\"Optimized solution for a single season\"\"\"\n",
    "        judge_pct = season_data['judge_data']['percentages']\n",
    "        judge_ranks = season_data['judge_data']['ranks']\n",
    "        active_mask = season_data['judge_data']['active_mask']\n",
    "        eliminated_idx = season_data['elimination_data']\n",
    "        rule_type = season_data['rule_type']\n",
    "        features = season_data['features']['matrix']\n",
    "        n_contestants, n_weeks = judge_pct.shape\n",
    "        \n",
    "        fan_pct = np.zeros((n_contestants, n_weeks))\n",
    "        \n",
    "        for t in range(n_weeks):\n",
    "            active_this_week = np.where(active_mask[:, t])[0]\n",
    "            n_active = len(active_this_week)\n",
    "            \n",
    "            if n_active == 0:\n",
    "                continue\n",
    "            \n",
    "            if eliminated_idx[t] is None or eliminated_idx[t] not in active_this_week:\n",
    "                fan_pct[active_this_week, t] = 1.0 / n_active\n",
    "                continue\n",
    "            \n",
    "            e_t = eliminated_idx[t]\n",
    "            e_t_idx_in_active = np.where(active_this_week == e_t)[0][0]\n",
    "            \n",
    "            if rule_type == 'percentage':\n",
    "                fan_pct_week = self._solve_percentage_method(\n",
    "                    judge_pct[active_this_week, t], \n",
    "                    e_t_idx_in_active,\n",
    "                    features[active_this_week, :],\n",
    "                    n_active\n",
    "                )\n",
    "                fan_pct[active_this_week, t] = fan_pct_week\n",
    "            \n",
    "            elif rule_type == 'rank':\n",
    "                fan_pct_week = self._solve_rank_method(\n",
    "                    judge_ranks[active_this_week, t],\n",
    "                    e_t_idx_in_active,\n",
    "                    features[active_this_week, :],\n",
    "                    n_active\n",
    "                )\n",
    "                fan_pct[active_this_week, t] = fan_pct_week\n",
    "        \n",
    "        # Apply smoothing\n",
    "        fan_pct = self._apply_temporal_smoothing(fan_pct, active_mask)\n",
    "        \n",
    "        return fan_pct\n",
    "    \n",
    "    def _solve_percentage_method(self, judge_pct_week, eliminated_idx, features, n_active):\n",
    "        \"\"\"Solve for percentage method weeks\"\"\"\n",
    "        fan_pct = np.ones(n_active) / n_active\n",
    "        \n",
    "        # Feature adjustment\n",
    "        if features.shape[1] > 1:\n",
    "            feature_weights = np.sum(features[:, :-1], axis=1)  # Exclude intercept\n",
    "            if np.std(feature_weights) > 0:\n",
    "                feature_weights = (feature_weights - np.min(feature_weights)) / (np.max(feature_weights) - np.min(feature_weights))\n",
    "                fan_pct += 0.15 * feature_weights\n",
    "        \n",
    "        # Ensure eliminated contestant has lowest total\n",
    "        total_pct = judge_pct_week + fan_pct\n",
    "        eliminated_total = total_pct[eliminated_idx]\n",
    "        \n",
    "        if not np.isclose(eliminated_total, np.min(total_pct)):\n",
    "            fan_pct[eliminated_idx] *= 0.5\n",
    "            \n",
    "            others = [i for i in range(n_active) if i != eliminated_idx]\n",
    "            if others:\n",
    "                increase = (fan_pct[eliminated_idx] * 0.5) / len(others)\n",
    "                fan_pct[others] += increase\n",
    "        \n",
    "        # Apply constraints\n",
    "        fan_pct = np.maximum(fan_pct, 0.01)\n",
    "        fan_pct = fan_pct / np.sum(fan_pct)\n",
    "        \n",
    "        return fan_pct\n",
    "    \n",
    "    def _solve_rank_method(self, judge_ranks_week, eliminated_idx, features, n_active):\n",
    "        \"\"\"Solve for rank method weeks\"\"\"\n",
    "        max_rank = np.max(judge_ranks_week[judge_ranks_week > 0])\n",
    "        judge_scores = max_rank + 1 - judge_ranks_week\n",
    "        judge_scores = judge_scores / np.sum(judge_scores)\n",
    "        \n",
    "        fan_pct = np.ones(n_active) / n_active\n",
    "        \n",
    "        # Feature adjustment\n",
    "        if features.shape[1] > 1:\n",
    "            feature_weights = np.sum(features[:, :-1], axis=1)\n",
    "            if np.std(feature_weights) > 0:\n",
    "                feature_weights = (feature_weights - np.min(feature_weights)) / (np.max(feature_weights) - np.min(feature_weights))\n",
    "                fan_pct += 0.15 * feature_weights\n",
    "        \n",
    "        # Ensure eliminated contestant has worst rank\n",
    "        fan_pct[eliminated_idx] = np.min(fan_pct) * 0.7\n",
    "        \n",
    "        # Apply constraints\n",
    "        fan_pct = np.maximum(fan_pct, 0.01)\n",
    "        fan_pct = fan_pct / np.sum(fan_pct)\n",
    "        \n",
    "        return fan_pct\n",
    "    \n",
    "    def _apply_temporal_smoothing(self, fan_pct, active_mask):\n",
    "        \"\"\"Apply temporal smoothing to fan percentages\"\"\"\n",
    "        n_contestants, n_weeks = fan_pct.shape\n",
    "        \n",
    "        smoothed = fan_pct.copy()\n",
    "        \n",
    "        for i in range(n_contestants):\n",
    "            active_weeks = np.where(active_mask[i, :])[0]\n",
    "            if len(active_weeks) < 3:\n",
    "                continue\n",
    "            \n",
    "            for j in range(1, len(active_weeks) - 1):\n",
    "                week_idx = active_weeks[j]\n",
    "                prev_week = active_weeks[j-1]\n",
    "                next_week = active_weeks[j+1]\n",
    "                \n",
    "                smoothed[i, week_idx] = 0.7 * fan_pct[i, week_idx] + 0.15 * fan_pct[i, prev_week] + 0.15 * fan_pct[i, next_week]\n",
    "        \n",
    "        # Renormalize each week\n",
    "        for t in range(n_weeks):\n",
    "            active_this_week = np.where(active_mask[:, t])[0]\n",
    "            if len(active_this_week) > 0:\n",
    "                smoothed[active_this_week, t] = smoothed[active_this_week, t] / np.sum(smoothed[active_this_week, t])\n",
    "        \n",
    "        return smoothed\n",
    "    \n",
    "    def _calculate_consistency(self, fan_pct, season_data):\n",
    "        \"\"\"Calculate consistency of predictions\"\"\"\n",
    "        judge_pct = season_data['judge_data']['percentages']\n",
    "        judge_ranks = season_data['judge_data']['ranks']\n",
    "        eliminated_idx = season_data['elimination_data']\n",
    "        active_mask = season_data['judge_data']['active_mask']\n",
    "        rule_type = season_data['rule_type']\n",
    "        \n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for t in range(fan_pct.shape[1]):\n",
    "            if eliminated_idx[t] is None:\n",
    "                continue\n",
    "            \n",
    "            active_this_week = np.where(active_mask[:, t])[0]\n",
    "            if len(active_this_week) <= 1:\n",
    "                continue\n",
    "            \n",
    "            e_t = eliminated_idx[t]\n",
    "            \n",
    "            if rule_type == 'percentage':\n",
    "                total_pct = judge_pct[active_this_week, t] + fan_pct[active_this_week, t]\n",
    "                pred_elim = active_this_week[np.argmin(total_pct)]\n",
    "                if pred_elim == e_t:\n",
    "                    correct += 1\n",
    "            \n",
    "            elif rule_type == 'rank':\n",
    "                fan_pct_week = fan_pct[active_this_week, t]\n",
    "                pred_elim = active_this_week[np.argmin(fan_pct_week)]\n",
    "                if pred_elim == e_t:\n",
    "                    correct += 1\n",
    "            \n",
    "            total += 1\n",
    "        \n",
    "        return correct / total if total > 0 else 0.0\n",
    "\n",
    "# ==================== 3. RESULTS SAVER WITH PROPER MERGING ====================\n",
    "\n",
    "class ResultSaver:\n",
    "    \"\"\"Save results to files with proper merging\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir=\"fan_vote_predictions\"):\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        os.makedirs(os.path.join(output_dir, \"detailed\"), exist_ok=True)\n",
    "        \n",
    "    def save_all_results(self, all_predictions, all_seasons_data, original_data):\n",
    "        \"\"\"Save all results with proper merging\"\"\"\n",
    "        print(\"\\nSaving results...\")\n",
    "        \n",
    "        # 1. Create updated data with predictions\n",
    "        updated_data = self._merge_predictions_with_original(\n",
    "            all_predictions, all_seasons_data, original_data\n",
    "        )\n",
    "        \n",
    "        # 2. Save updated complete data\n",
    "        self._save_updated_data(updated_data)\n",
    "        \n",
    "        # 3. Save detailed predictions\n",
    "        self._save_detailed_predictions(all_predictions, all_seasons_data)\n",
    "        \n",
    "        # 4. Save summary report\n",
    "        self._save_summary_report(all_predictions, all_seasons_data)\n",
    "        \n",
    "        print(f\"\\n‚úì All results saved to {self.output_dir}/\")\n",
    "        \n",
    "        return updated_data\n",
    "    \n",
    "    def _merge_predictions_with_original(self, all_predictions, all_seasons_data, original_data):\n",
    "        \"\"\"Merge predictions back to original data\"\"\"\n",
    "        print(\"  Merging predictions with original data...\")\n",
    "        \n",
    "        # Create copy of original data\n",
    "        updated_data = original_data.copy()\n",
    "        \n",
    "        # Ensure unique index for matching\n",
    "        updated_data.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Add prediction columns for each season\n",
    "        for season_num, fan_pct in all_predictions.items():\n",
    "            if season_num not in all_seasons_data:\n",
    "                continue\n",
    "            \n",
    "            season_data = all_seasons_data[season_num]\n",
    "            n_weeks = fan_pct.shape[1]\n",
    "            \n",
    "            # Get indices for this season in original data\n",
    "            season_mask = updated_data['season'] == season_num\n",
    "            season_indices = updated_data[season_mask].index.tolist()\n",
    "            \n",
    "            # Check if indices match\n",
    "            if len(season_indices) != fan_pct.shape[0]:\n",
    "                print(f\"    ‚ö† Season {season_num}: Index mismatch ({len(season_indices)} vs {fan_pct.shape[0]})\")\n",
    "                # Try name-based matching\n",
    "                contestant_mapping = self._create_contestant_mapping(\n",
    "                    updated_data[season_mask], season_data\n",
    "                )\n",
    "            else:\n",
    "                # Direct index matching\n",
    "                contestant_mapping = {i: season_indices[i] for i in range(fan_pct.shape[0])}\n",
    "            \n",
    "            print(f\"    Season {season_num}: {len(contestant_mapping)} contestants matched\")\n",
    "            \n",
    "            # Add prediction columns for each week\n",
    "            for week in range(1, n_weeks + 1):\n",
    "                col_name_pct = f'Week{week}_Predicted_Fan_Pct'\n",
    "                col_name_votes = f'Week{week}_Predicted_Fan_Votes'\n",
    "                \n",
    "                # Initialize new columns\n",
    "                if col_name_pct not in updated_data.columns:\n",
    "                    updated_data[col_name_pct] = np.nan\n",
    "                if col_name_votes not in updated_data.columns:\n",
    "                    updated_data[col_name_votes] = np.nan\n",
    "                \n",
    "                # Add predictions for each contestant\n",
    "                for model_idx, original_idx in contestant_mapping.items():\n",
    "                    if model_idx < fan_pct.shape[0]:\n",
    "                        if season_data['judge_data']['active_mask'][model_idx, week-1]:\n",
    "                            fan_pct_value = fan_pct[model_idx, week-1]\n",
    "                            fan_votes_value = fan_pct_value * 10000000\n",
    "                            \n",
    "                            updated_data.at[original_idx, col_name_pct] = fan_pct_value\n",
    "                            updated_data.at[original_idx, col_name_votes] = fan_votes_value\n",
    "            \n",
    "            # Add season summary columns\n",
    "            for model_idx, original_idx in contestant_mapping.items():\n",
    "                if model_idx < fan_pct.shape[0]:\n",
    "                    active_weeks = season_data['judge_data']['active_mask'][model_idx, :]\n",
    "                    if np.any(active_weeks):\n",
    "                        avg_pct = np.mean(fan_pct[model_idx, active_weeks])\n",
    "                        total_votes = avg_pct * 10000000 * np.sum(active_weeks)\n",
    "                        \n",
    "                        updated_data.at[original_idx, f'Season{season_num}_Avg_Fan_Pct'] = avg_pct\n",
    "                        updated_data.at[original_idx, f'Season{season_num}_Total_Fan_Votes'] = total_votes\n",
    "                        updated_data.at[original_idx, f'Season{season_num}_Weeks_Active'] = np.sum(active_weeks)\n",
    "        \n",
    "        return updated_data\n",
    "    \n",
    "    def _create_contestant_mapping(self, original_season_data, season_data_info):\n",
    "        \"\"\"Create contestant mapping (via name matching)\"\"\"\n",
    "        mapping = {}\n",
    "        \n",
    "        # Get contestant info from original data\n",
    "        original_contestants = {}\n",
    "        for idx, row in original_season_data.iterrows():\n",
    "            name = row['celebrity_name'] if 'celebrity_name' in row else None\n",
    "            if name:\n",
    "                original_contestants[name] = idx\n",
    "        \n",
    "        # Get contestant info from model data\n",
    "        model_contestants = []\n",
    "        if 'contestant_info' in season_data_info:\n",
    "            for info in season_data_info['contestant_info']:\n",
    "                model_contestants.append(info['name'])\n",
    "        elif 'original_data' in season_data_info:\n",
    "            for idx, row in season_data_info['original_data'].iterrows():\n",
    "                name = row['celebrity_name'] if 'celebrity_name' in row else f'Contestant_{idx}'\n",
    "                model_contestants.append(name)\n",
    "        \n",
    "        # Perform name matching\n",
    "        for model_idx, model_name in enumerate(model_contestants):\n",
    "            if model_name in original_contestants:\n",
    "                mapping[model_idx] = original_contestants[model_name]\n",
    "            else:\n",
    "                # Try fuzzy matching\n",
    "                for orig_name, orig_idx in original_contestants.items():\n",
    "                    if self._names_match(model_name, orig_name):\n",
    "                        mapping[model_idx] = orig_idx\n",
    "                        break\n",
    "        \n",
    "        return mapping\n",
    "    \n",
    "    def _names_match(self, name1, name2):\n",
    "        \"\"\"Check if two names match (simple version)\"\"\"\n",
    "        name1_clean = str(name1).lower().strip()\n",
    "        name2_clean = str(name2).lower().strip()\n",
    "        \n",
    "        # Exact match\n",
    "        if name1_clean == name2_clean:\n",
    "            return True\n",
    "        \n",
    "        # Partial match\n",
    "        if name1_clean in name2_clean or name2_clean in name1_clean:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def _save_updated_data(self, updated_data):\n",
    "        \"\"\"Save updated data\"\"\"\n",
    "        # Save as Excel\n",
    "        excel_file = os.path.join(self.output_dir, \"merged_data_with_predictions.xlsx\")\n",
    "        updated_data.to_excel(excel_file, index=False)\n",
    "        print(f\"  ‚úì Updated data saved to: {excel_file}\")\n",
    "        \n",
    "        # Save as CSV (if needed)\n",
    "        csv_file = os.path.join(self.output_dir, \"merged_data_with_predictions.csv\")\n",
    "        updated_data.to_csv(csv_file, index=False)\n",
    "        print(f\"  ‚úì CSV version saved to: {csv_file}\")\n",
    "        \n",
    "        # Show data preview\n",
    "        print(f\"\\n  Preview of updated data:\")\n",
    "        print(f\"    Total rows: {len(updated_data)}\")\n",
    "        print(f\"    Total columns: {len(updated_data.columns)}\")\n",
    "        \n",
    "        # Show prediction columns\n",
    "        pred_cols = [col for col in updated_data.columns if 'Predicted' in col]\n",
    "        print(f\"    Prediction columns added: {len(pred_cols)}\")\n",
    "        \n",
    "        # Show first few rows\n",
    "        print(f\"\\n  Sample of predictions (first 5 rows, showing key columns):\")\n",
    "        sample_cols = ['season', 'celebrity_name']\n",
    "        if len(pred_cols) > 0:\n",
    "            sample_cols.extend(pred_cols[:3])  # Only show first 3 prediction columns\n",
    "        \n",
    "        sample = updated_data[sample_cols].head()\n",
    "        print(sample.to_string())\n",
    "        \n",
    "        # Check for duplicates\n",
    "        duplicates = updated_data.duplicated(subset=['season', 'celebrity_name']).sum()\n",
    "        if duplicates > 0:\n",
    "            print(f\"\\n  ‚ö† Warning: {duplicates} duplicate records found in final data\")\n",
    "    \n",
    "    def _save_detailed_predictions(self, all_predictions, all_seasons_data):\n",
    "        \"\"\"Save detailed predictions\"\"\"\n",
    "        print(\"\\n  Saving detailed predictions...\")\n",
    "        \n",
    "        for season_num, fan_pct in all_predictions.items():\n",
    "            if season_num not in all_seasons_data:\n",
    "                continue\n",
    "            \n",
    "            season_data = all_seasons_data[season_num]\n",
    "            rows = []\n",
    "            n_contestants, n_weeks = fan_pct.shape\n",
    "            \n",
    "            for i in range(n_contestants):\n",
    "                # Get contestant info\n",
    "                contestant_name = f\"Contestant_{i}\"\n",
    "                if 'contestant_info' in season_data and i < len(season_data['contestant_info']):\n",
    "                    contestant_name = season_data['contestant_info'][i]['name']\n",
    "                elif 'original_data' in season_data and i < len(season_data['original_data']):\n",
    "                    contestant_name = season_data['original_data'].iloc[i]['celebrity_name'] if 'celebrity_name' in season_data['original_data'].columns else f\"Contestant_{i}\"\n",
    "                \n",
    "                for t in range(n_weeks):\n",
    "                    if season_data['judge_data']['active_mask'][i, t]:\n",
    "                        row = {\n",
    "                            'season': season_num,\n",
    "                            'week': t + 1,\n",
    "                            'contestant_id': i,\n",
    "                            'contestant_name': str(contestant_name)[:50],\n",
    "                            'predicted_fan_percentage': fan_pct[i, t],\n",
    "                            'predicted_fan_votes': fan_pct[i, t] * 10000000,\n",
    "                            'rule_type': season_data['rule_type'],\n",
    "                            'judge_score': season_data['judge_data']['scores'][i, t],\n",
    "                            'judge_percentage': season_data['judge_data']['percentages'][i, t],\n",
    "                            'active': True\n",
    "                        }\n",
    "                        rows.append(row)\n",
    "            \n",
    "            if rows:\n",
    "                df = pd.DataFrame(rows)\n",
    "                filename = os.path.join(self.output_dir, \"detailed\", f\"season_{season_num:02d}_detailed.csv\")\n",
    "                df.to_csv(filename, index=False)\n",
    "                print(f\"    ‚úì Season {season_num}: {len(rows)} detailed records saved\")\n",
    "    \n",
    "    def _save_summary_report(self, all_predictions, all_seasons_data):\n",
    "        \"\"\"Save summary report\"\"\"\n",
    "        summary_rows = []\n",
    "        \n",
    "        for season_num, fan_pct in all_predictions.items():\n",
    "            if season_num not in all_seasons_data:\n",
    "                continue\n",
    "            \n",
    "            season_data = all_seasons_data[season_num]\n",
    "            n_contestants, n_weeks = fan_pct.shape\n",
    "            \n",
    "            # Calculate season statistics\n",
    "            total_active_weeks = 0\n",
    "            total_predicted_votes = 0\n",
    "            \n",
    "            for i in range(n_contestants):\n",
    "                active_weeks = np.sum(season_data['judge_data']['active_mask'][i, :])\n",
    "                total_active_weeks += active_weeks\n",
    "                if active_weeks > 0:\n",
    "                    avg_pct = np.mean(fan_pct[i, season_data['judge_data']['active_mask'][i, :]])\n",
    "                    total_predicted_votes += avg_pct * 10000000 * active_weeks\n",
    "            \n",
    "            summary_rows.append({\n",
    "                'season': season_num,\n",
    "                'rule_type': season_data['rule_type'],\n",
    "                'n_contestants': n_contestants,\n",
    "                'n_weeks': n_weeks,\n",
    "                'total_active_weeks': total_active_weeks,\n",
    "                'total_predicted_votes': total_predicted_votes,\n",
    "                'avg_votes_per_week': total_predicted_votes / total_active_weeks if total_active_weeks > 0 else 0\n",
    "            })\n",
    "        \n",
    "        if summary_rows:\n",
    "            df = pd.DataFrame(summary_rows)\n",
    "            filename = os.path.join(self.output_dir, \"season_summary.csv\")\n",
    "            df.to_csv(filename, index=False)\n",
    "            print(f\"  ‚úì Season summary saved: {filename}\")\n",
    "\n",
    "# ==================== 4. MAIN PIPELINE ====================\n",
    "\n",
    "class FanVoteEstimationPipeline:\n",
    "    \"\"\"Complete pipeline for fan vote estimation\"\"\"\n",
    "    \n",
    "    def __init__(self, data_file, total_votes=10000000):\n",
    "        self.data_file = data_file\n",
    "        self.total_votes = total_votes\n",
    "        self.processor = None\n",
    "        self.model = None\n",
    "        self.saver = None\n",
    "        self.original_data = None\n",
    "        self.results = {}\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"Run complete pipeline\"\"\"\n",
    "        print(\"=\" * 80)\n",
    "        print(\"2026 MCM PROBLEM C - FAN VOTE ESTIMATION\")\n",
    "        print(f\"Assumed total votes per week: {self.total_votes:,}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        try:\n",
    "            # 1. Data Preparation\n",
    "            print(\"\\n1. DATA PREPARATION\")\n",
    "            print(\"-\" * 40)\n",
    "            self.processor = EnhancedDataProcessor(self.data_file)\n",
    "            self.original_data = self.processor.load_and_clean_data()\n",
    "            \n",
    "            if self.original_data is None:\n",
    "                raise ValueError(\"Failed to load data\")\n",
    "            \n",
    "            self.processor.determine_season_rules_enhanced()\n",
    "            all_seasons_data = self.processor.prepare_all_seasons_data()\n",
    "            \n",
    "            # 2. Modeling\n",
    "            print(\"\\n2. MODELING - FAN VOTE ESTIMATION\")\n",
    "            print(\"-\" * 40)\n",
    "            self.model = ImprovedOptimizationModel(total_votes=self.total_votes)\n",
    "            all_predictions = self.model.solve_all_seasons(all_seasons_data)\n",
    "            \n",
    "            # 3. Save Results\n",
    "            print(\"\\n3. SAVING RESULTS\")\n",
    "            print(\"-\" * 40)\n",
    "            self.saver = ResultSaver()\n",
    "            updated_data = self.saver.save_all_results(\n",
    "                all_predictions, all_seasons_data, self.original_data\n",
    "            )\n",
    "            \n",
    "            # Store results\n",
    "            self.results = {\n",
    "                'predictions': all_predictions,\n",
    "                'all_seasons_data': all_seasons_data,\n",
    "                'updated_data': updated_data\n",
    "            }\n",
    "            \n",
    "            # Final summary\n",
    "            self._print_final_summary(updated_data)\n",
    "            \n",
    "            return self.results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "    \n",
    "    def _print_final_summary(self, updated_data):\n",
    "        \"\"\"Print final summary\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"ANALYSIS COMPLETE - FINAL SUMMARY\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        print(f\"\\nüìä DATA SUMMARY:\")\n",
    "        print(f\"  Total records: {len(updated_data)}\")\n",
    "        print(f\"  Seasons analyzed: {len(updated_data['season'].unique())}\")\n",
    "        \n",
    "        # Show prediction columns\n",
    "        pred_pct_cols = [col for col in updated_data.columns if 'Predicted_Fan_Pct' in col]\n",
    "        pred_votes_cols = [col for col in updated_data.columns if 'Predicted_Fan_Votes' in col]\n",
    "        \n",
    "        print(f\"\\nüìà PREDICTIONS GENERATED:\")\n",
    "        print(f\"  Fan percentage columns: {len(pred_pct_cols)}\")\n",
    "        print(f\"  Fan vote columns: {len(pred_votes_cols)}\")\n",
    "        \n",
    "        if pred_pct_cols:\n",
    "            # Show sample data\n",
    "            sample_data = updated_data[['season', 'celebrity_name'] + pred_pct_cols[:3]].head(10)\n",
    "            print(f\"\\nüìã SAMPLE OF PREDICTIONS (First 10 rows):\")\n",
    "            print(sample_data.to_string(index=False))\n",
    "            \n",
    "            # Check prediction validity\n",
    "            print(f\"\\n‚úÖ PREDICTION VALIDATION:\")\n",
    "            for col in pred_pct_cols[:2]:  # Check first two weeks\n",
    "                if col in updated_data.columns:\n",
    "                    valid_pct = updated_data[col].notna().sum()\n",
    "                    avg_pct = updated_data[col].mean()\n",
    "                    print(f\"  {col}: {valid_pct} valid predictions, average: {avg_pct:.2%}\")\n",
    "        \n",
    "        print(f\"\\nüìÅ OUTPUT FILES:\")\n",
    "        print(f\"  1. Main file with predictions: fan_vote_predictions/merged_data_with_predictions.xlsx\")\n",
    "        print(f\"  2. Detailed predictions: fan_vote_predictions/detailed/season_XX_detailed.csv\")\n",
    "        print(f\"  3. Season summary: fan_vote_predictions/season_summary.csv\")\n",
    "        \n",
    "        print(f\"\\nüí° NEXT STEPS:\")\n",
    "        print(f\"  1. Open 'merged_data_with_predictions.xlsx' to see all predictions\")\n",
    "        print(f\"  2. Use the predicted fan votes for Tasks 2-4 of the problem\")\n",
    "        print(f\"  3. Check 'season_summary.csv' for overall statistics\")\n",
    "\n",
    "# ==================== 5. MAIN EXECUTION ====================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    \n",
    "    # Configuration\n",
    "    DATA_FILE = \"merged_ranking_percentage.xlsx\"  # Your data file\n",
    "    TOTAL_VOTES = 10000000  # 10 million total votes\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"2026 MCM PROBLEM C - FAN VOTE ESTIMATION\")\n",
    "    print(f\"Assumed total votes per week: {TOTAL_VOTES:,}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Create and run pipeline\n",
    "    pipeline = FanVoteEstimationPipeline(DATA_FILE, TOTAL_VOTES)\n",
    "    results = pipeline.run()\n",
    "    \n",
    "    if results and 'updated_data' in results:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"‚úÖ FAN VOTE ESTIMATION COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Show key information\n",
    "        updated_data = results['updated_data']\n",
    "        \n",
    "        # Check data quality\n",
    "        print(f\"\\nüîç DATA QUALITY CHECK:\")\n",
    "        print(f\"  Total unique contestants: {updated_data[['season', 'celebrity_name']].drop_duplicates().shape[0]}\")\n",
    "        \n",
    "        # Check duplicates\n",
    "        duplicates = updated_data.duplicated(subset=['season', 'celebrity_name']).sum()\n",
    "        if duplicates == 0:\n",
    "            print(f\"  ‚úì No duplicate contestants found\")\n",
    "        else:\n",
    "            print(f\"  ‚ö† {duplicates} duplicate contestants found\")\n",
    "        \n",
    "        # Show file location\n",
    "        import os\n",
    "        abs_path = os.path.abspath(\"fan_vote_predictions/merged_data_with_predictions.xlsx\")\n",
    "        print(f\"\\nüìÇ Main output file location:\")\n",
    "        print(f\"  {abs_path}\")\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"‚ùå ANALYSIS FAILED\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a21666",
   "metadata": {},
   "source": [
    "2nd problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cf1f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPLETE DWTS JUDGE VS FAN PERCENTAGE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Load the original data\n",
    "print(\"\\n1. Loading original DWTS data...\")\n",
    "df = pd.read_csv('2026_MCM_Problem_C_Data.csv', encoding='utf-8')\n",
    "print(f\"   Loaded {len(df)} records from the original dataset\")\n",
    "\n",
    "# 2. Clean and prepare the data\n",
    "print(\"\\n2. Cleaning and preparing data...\")\n",
    "\n",
    "# Convert N/A values to NaN\n",
    "df = df.replace('N/A', np.nan)\n",
    "\n",
    "# Create a clean copy for calculations\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 3. Calculate total judge scores for each contestant\n",
    "print(\"\\n3. Calculating total judge scores...\")\n",
    "\n",
    "# Find all judge score columns\n",
    "judge_columns = [col for col in df_clean.columns if 'judge' in col.lower() and 'score' in col.lower()]\n",
    "\n",
    "# Convert all judge score columns to numeric\n",
    "for col in judge_columns:\n",
    "    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "\n",
    "# Calculate total judge score for each contestant\n",
    "df_clean['total_judge_score'] = df_clean[judge_columns].sum(axis=1)\n",
    "\n",
    "print(f\"   Found {len(judge_columns)} judge score columns\")\n",
    "print(f\"   Total judge scores calculated for {len(df_clean)} contestants\")\n",
    "\n",
    "# 4. Calculate judge percentages\n",
    "print(\"\\n4. Calculating judge percentages...\")\n",
    "total_all_judge_scores = df_clean['total_judge_score'].sum()\n",
    "df_clean['judge_percentage'] = (df_clean['total_judge_score'] / total_all_judge_scores) * 100\n",
    "\n",
    "# 5. Estimate fan votes (this is a critical modeling step)\n",
    "print(\"\\n5. Estimating fan votes based on placement and results...\")\n",
    "\n",
    "# First, let's estimate fan votes using several factors\n",
    "df_clean['estimated_fan_votes'] = 0\n",
    "\n",
    "# Create a scoring system based on multiple factors\n",
    "for idx, row in df_clean.iterrows():\n",
    "    fan_score = 0\n",
    "    \n",
    "    # 1. Base on final placement (better placement = more fans)\n",
    "    if pd.notna(row['placement']):\n",
    "        try:\n",
    "            placement = float(row['placement'])\n",
    "            # Higher placement (lower number) gets more points\n",
    "            fan_score += (11 - min(placement, 10)) * 1000  # Max 10,000 points\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # 2. Bonus for winners and finalists\n",
    "    results_str = str(row['results']).lower()\n",
    "    if '1st' in results_str or 'winner' in results_str:\n",
    "        fan_score += 5000\n",
    "    elif '2nd' in results_str:\n",
    "        fan_score += 4000\n",
    "    elif '3rd' in results_str:\n",
    "        fan_score += 3000\n",
    "    elif 'final' in results_str or 'finalist' in results_str:\n",
    "        fan_score += 2000\n",
    "    \n",
    "    # 3. Consider how long they lasted in the competition\n",
    "    # Extract week number from results if possible\n",
    "    results_text = str(row['results']).lower()\n",
    "    if 'week' in results_text:\n",
    "        try:\n",
    "            # Find the week number\n",
    "            for word in results_text.split():\n",
    "                if word.isdigit():\n",
    "                    week_num = int(word)\n",
    "                    # More weeks = more exposure = more fans\n",
    "                    fan_score += week_num * 500\n",
    "                    break\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # 4. Age factor (younger contestants might have more social media fans)\n",
    "    if pd.notna(row['celebrity_age_during_season']):\n",
    "        age = float(row['celebrity_age_during_season'])\n",
    "        # Younger contestants get a slight bonus (simulating social media following)\n",
    "        if age < 30:\n",
    "            fan_score += 1000\n",
    "        elif age < 50:\n",
    "            fan_score += 500\n",
    "    \n",
    "    # 5. Industry factor (some industries have larger fan bases)\n",
    "    industry = str(row['celebrity_industry']).lower()\n",
    "    if 'actor' in industry or 'actress' in industry:\n",
    "        fan_score += 2000\n",
    "    elif 'singer' in industry or 'rapper' in industry:\n",
    "        fan_score += 2500  # Music artists often have strong fan bases\n",
    "    elif 'athlete' in industry:\n",
    "        fan_score += 1500\n",
    "    elif 'tv' in industry or 'reality' in industry:\n",
    "        fan_score += 3000  # TV personalities often have dedicated fan bases\n",
    "    \n",
    "    # 6. Season number (later seasons had more viewers)\n",
    "    if pd.notna(row['season']):\n",
    "        try:\n",
    "            season_num = float(row['season'])\n",
    "            # Later seasons had more viewers\n",
    "            fan_score += min(season_num, 30) * 100\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Add some randomness to simulate real-world variation\n",
    "    np.random.seed(idx)  # For reproducibility\n",
    "    fan_score += np.random.randint(0, 2000)\n",
    "    \n",
    "    # Ensure minimum fan score\n",
    "    fan_score = max(fan_score, 100)\n",
    "    \n",
    "    df_clean.at[idx, 'estimated_fan_votes'] = fan_score\n",
    "\n",
    "print(f\"   Fan votes estimated for {len(df_clean)} contestants\")\n",
    "\n",
    "# 6. Calculate fan percentages\n",
    "print(\"\\n6. Calculating fan percentages...\")\n",
    "total_all_fan_votes = df_clean['estimated_fan_votes'].sum()\n",
    "df_clean['fan_percentage'] = (df_clean['estimated_fan_votes'] / total_all_fan_votes) * 100\n",
    "\n",
    "# 7. Calculate total percentage (judge + fan)\n",
    "print(\"\\n7. Calculating total percentages...\")\n",
    "df_clean['total_percentage'] = df_clean['judge_percentage'] + df_clean['fan_percentage']\n",
    "\n",
    "# 8. Sort by total percentage (highest to lowest)\n",
    "print(\"\\n8. Sorting by total percentage...\")\n",
    "df_clean = df_clean.sort_values('total_percentage', ascending=False)\n",
    "\n",
    "# 9. Save the complete percentage data\n",
    "print(\"\\n9. Saving complete percentage data...\")\n",
    "percentage_df = df_clean[['celebrity_name', 'total_judge_score', 'judge_percentage', \n",
    "                         'estimated_fan_votes', 'fan_percentage', 'total_percentage']].copy()\n",
    "\n",
    "percentage_df.to_csv('DWTS_Judge_Fan_Percentage_Data.csv', index=False, encoding='utf-8')\n",
    "print(f\"   ‚úì Complete percentage data saved: DWTS_Judge_Fan_Percentage_Data.csv\")\n",
    "print(f\"   Contains {len(percentage_df)} contestants\")\n",
    "\n",
    "# ======================================================================\n",
    "# PART 2: CREATE SIMPLIFIED TABLE\n",
    "# ======================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING SIMPLIFIED JUDGE VS FAN PERCENTAGE TABLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 10. Select only required columns for simplified table\n",
    "print(\"\\n10. Selecting required columns for simplified table...\")\n",
    "\n",
    "required_columns = [\n",
    "    'celebrity_name',\n",
    "    'total_judge_score', \n",
    "    'judge_percentage',\n",
    "    'estimated_fan_votes',\n",
    "    'fan_percentage',\n",
    "    'total_percentage'\n",
    "]\n",
    "\n",
    "simplified_df = percentage_df[required_columns].copy()\n",
    "\n",
    "# 11. Format the data\n",
    "print(\"\\n11. Formatting data...\")\n",
    "\n",
    "# Keep numeric values for calculations\n",
    "numeric_df = simplified_df.copy()\n",
    "\n",
    "# Create display version with formatted percentages\n",
    "display_df = simplified_df.copy()\n",
    "\n",
    "# Format percentages to 2 decimal places\n",
    "display_df['judge_percentage'] = display_df['judge_percentage'].apply(lambda x: f\"{x:.2f}%\")\n",
    "display_df['fan_percentage'] = display_df['fan_percentage'].apply(lambda x: f\"{x:.2f}%\")\n",
    "display_df['total_percentage'] = display_df['total_percentage'].apply(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "# Format numbers with commas\n",
    "display_df['total_judge_score'] = display_df['total_judge_score'].apply(lambda x: f\"{x:,.0f}\")\n",
    "display_df['estimated_fan_votes'] = display_df['estimated_fan_votes'].apply(lambda x: f\"{x:,.0f}\")\n",
    "\n",
    "# 12. Add total row\n",
    "print(\"\\n12. Adding total row...\")\n",
    "\n",
    "# Calculate totals\n",
    "total_judge_score = numeric_df['total_judge_score'].sum()\n",
    "total_fan_votes = numeric_df['estimated_fan_votes'].sum()\n",
    "\n",
    "# For percentages, we need to calculate properly\n",
    "total_judge_percentage = 100.00\n",
    "total_fan_percentage = 100.00\n",
    "total_combined_percentage = 200.00\n",
    "\n",
    "# Create total row for numeric data\n",
    "total_row_numeric = pd.DataFrame([{\n",
    "    'celebrity_name': 'TOTAL',\n",
    "    'total_judge_score': total_judge_score,\n",
    "    'judge_percentage': total_judge_percentage,\n",
    "    'estimated_fan_votes': total_fan_votes,\n",
    "    'fan_percentage': total_fan_percentage,\n",
    "    'total_percentage': total_combined_percentage\n",
    "}])\n",
    "\n",
    "# Create total row for display data\n",
    "total_row_display = pd.DataFrame([{\n",
    "    'celebrity_name': 'TOTAL',\n",
    "    'total_judge_score': f\"{total_judge_score:,.0f}\",\n",
    "    'judge_percentage': f\"{total_judge_percentage:.2f}%\",\n",
    "    'estimated_fan_votes': f\"{total_fan_votes:,.0f}\",\n",
    "    'fan_percentage': f\"{total_fan_percentage:.2f}%\",\n",
    "    'total_percentage': f\"{total_combined_percentage:.2f}%\"\n",
    "}])\n",
    "\n",
    "# 13. Combine data with totals\n",
    "print(\"\\n13. Combining data with totals...\")\n",
    "\n",
    "final_numeric_df = pd.concat([numeric_df, total_row_numeric], ignore_index=True)\n",
    "final_display_df = pd.concat([display_df, total_row_display], ignore_index=True)\n",
    "\n",
    "# 14. Rename columns for clarity\n",
    "print(\"\\n14. Renaming columns...\")\n",
    "\n",
    "column_names = {\n",
    "    'celebrity_name': 'Player Name',\n",
    "    'total_judge_score': 'Total Judge Score',\n",
    "    'judge_percentage': 'Judge Score %',\n",
    "    'estimated_fan_votes': 'Estimated Fan Votes',\n",
    "    'fan_percentage': 'Fan Vote %', \n",
    "    'total_percentage': 'Total %'\n",
    "}\n",
    "\n",
    "final_numeric_df = final_numeric_df.rename(columns=column_names)\n",
    "final_display_df = final_display_df.rename(columns=column_names)\n",
    "\n",
    "# 15. Save the files\n",
    "print(\"\\n15. Saving simplified tables...\")\n",
    "\n",
    "# Save numeric version (for calculations)\n",
    "final_numeric_df.to_csv('DWTS_Simplified_Percentage_Table_Numeric.csv', index=False, encoding='utf-8')\n",
    "print(f\"   ‚úì Numeric table saved: DWTS_Simplified_Percentage_Table_Numeric.csv\")\n",
    "\n",
    "# Save display version (for viewing)\n",
    "final_display_df.to_csv('DWTS_Simplified_Percentage_Table_Display.csv', index=False, encoding='utf-8')\n",
    "print(f\"   ‚úì Display table saved: DWTS_Simplified_Percentage_Table_Display.csv\")\n",
    "\n",
    "# 16. Display sample of the table\n",
    "print(\"\\n16. Sample of the simplified table (first 10 rows + total):\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "# Display first 10 rows + total row\n",
    "sample_display = pd.concat([final_display_df.head(10), final_display_df.tail(1)], ignore_index=True)\n",
    "\n",
    "pd.set_option('display.width', 120)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(sample_display.to_string(index=False))\n",
    "\n",
    "# 17. Create summary statistics\n",
    "print(\"\\n17. Creating summary statistics...\")\n",
    "\n",
    "# Calculate some key metrics from the data (excluding the TOTAL row)\n",
    "data_without_total = final_numeric_df[final_numeric_df['Player Name'] != 'TOTAL']\n",
    "\n",
    "summary_stats = {\n",
    "    'Statistic': [\n",
    "        'Number of Players',\n",
    "        'Average Total Judge Score',\n",
    "        'Average Judge Score %',\n",
    "        'Average Estimated Fan Votes',\n",
    "        'Average Fan Vote %',\n",
    "        'Average Total %',\n",
    "        'Highest Judge Score %',\n",
    "        'Highest Fan Vote %',\n",
    "        'Highest Total %',\n",
    "        'Median Judge Score %',\n",
    "        'Median Fan Vote %'\n",
    "    ],\n",
    "    'Value': [\n",
    "        len(data_without_total),\n",
    "        f\"{data_without_total['Total Judge Score'].mean():,.0f}\",\n",
    "        f\"{data_without_total['Judge Score %'].mean():.2f}%\",\n",
    "        f\"{data_without_total['Estimated Fan Votes'].mean():,.0f}\",\n",
    "        f\"{data_without_total['Fan Vote %'].mean():.2f}%\",\n",
    "        f\"{data_without_total['Total %'].mean():.2f}%\",\n",
    "        f\"{data_without_total['Judge Score %'].max():.2f}%\",\n",
    "        f\"{data_without_total['Fan Vote %'].max():.2f}%\",\n",
    "        f\"{data_without_total['Total %'].max():.2f}%\",\n",
    "        f\"{data_without_total['Judge Score %'].median():.2f}%\",\n",
    "        f\"{data_without_total['Fan Vote %'].median():.2f}%\"\n",
    "    ],\n",
    "    'Player': [\n",
    "        '',\n",
    "        data_without_total.loc[data_without_total['Total Judge Score'].idxmax(), 'Player Name'],\n",
    "        data_without_total.loc[data_without_total['Judge Score %'].idxmax(), 'Player Name'],\n",
    "        data_without_total.loc[data_without_total['Estimated Fan Votes'].idxmax(), 'Player Name'],\n",
    "        data_without_total.loc[data_without_total['Fan Vote %'].idxmax(), 'Player Name'],\n",
    "        data_without_total.loc[data_without_total['Total %'].idxmax(), 'Player Name'],\n",
    "        data_without_total.loc[data_without_total['Judge Score %'].idxmax(), 'Player Name'],\n",
    "        data_without_total.loc[data_without_total['Fan Vote %'].idxmax(), 'Player Name'],\n",
    "        data_without_total.loc[data_without_total['Total %'].idxmax(), 'Player Name'],\n",
    "        '',\n",
    "        ''\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "summary_df.to_csv('DWTS_Percentage_Summary.csv', index=False, encoding='utf-8')\n",
    "print(f\"\\n   ‚úì Summary statistics saved: DWTS_Percentage_Summary.csv\")\n",
    "\n",
    "# 18. Check controversial players\n",
    "print(\"\\n18. Analyzing controversial players...\")\n",
    "\n",
    "controversial_players = ['Jerry Rice', 'Bobby Bones', 'Bristol Palin', 'Billy Ray Cyrus']\n",
    "\n",
    "print(\"\\nControversial players analysis (players where fan support differed significantly from judge scores):\")\n",
    "for player in controversial_players:\n",
    "    player_data = final_numeric_df[final_numeric_df['Player Name'] == player]\n",
    "    if len(player_data) > 0:\n",
    "        row = player_data.iloc[0]\n",
    "        print(f\"\\n   {player}:\")\n",
    "        print(f\"      Judge Score: {row['Total Judge Score']:,.0f} ({row['Judge Score %']:.2f}%)\")\n",
    "        print(f\"      Fan Votes: {row['Estimated Fan Votes']:,.0f} ({row['Fan Vote %']:.2f}%)\")\n",
    "        print(f\"      Total: {row['Total %']:.2f}%\")\n",
    "        if row['Judge Score %'] > 0:\n",
    "            ratio = row['Fan Vote %'] / row['Judge Score %']\n",
    "            print(f\"      Fan/Judge Ratio: {ratio:.2f}:1\")\n",
    "\n",
    "# 19. Create verification check\n",
    "print(\"\\n19. Data verification:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Check if percentages sum correctly\n",
    "judge_percent_sum = data_without_total['Judge Score %'].sum()\n",
    "fan_percent_sum = data_without_total['Fan Vote %'].sum()\n",
    "total_percent_sum = data_without_total['Total %'].sum()\n",
    "\n",
    "print(f\"Sum of Judge Score % (should be ~100%): {judge_percent_sum:.2f}%\")\n",
    "print(f\"Sum of Fan Vote % (should be ~100%): {fan_percent_sum:.2f}%\")\n",
    "print(f\"Sum of Total % (should be ~200%): {total_percent_sum:.2f}%\")\n",
    "\n",
    "# 20. Quick analysis example\n",
    "print(\"\\n20. Quick analysis example:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Find top 5 players by fan-to-judge ratio\n",
    "data_without_total['Fan_Judge_Ratio'] = data_without_total['Fan Vote %'] / data_without_total['Judge Score %']\n",
    "top_ratios = data_without_total.nlargest(5, 'Fan_Judge_Ratio')[['Player Name', 'Judge Score %', 'Fan Vote %', 'Fan_Judge_Ratio']]\n",
    "\n",
    "print(\"\\nTop 5 players by Fan/Judge Ratio (highest fan influence relative to judges):\")\n",
    "for _, row in top_ratios.iterrows():\n",
    "    print(f\"  {row['Player Name']}: Judge {row['Judge Score %']:.2f}%, Fan {row['Fan Vote %']:.2f}%, Ratio: {row['Fan_Judge_Ratio']:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE! FILES CREATED:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "1. DWTS_Judge_Fan_Percentage_Data.csv - Complete percentage data\n",
    "2. DWTS_Simplified_Percentage_Table_Numeric.csv - Numeric table for calculations\n",
    "3. DWTS_Simplified_Percentage_Table_Display.csv - Formatted table for viewing/reports\n",
    "4. DWTS_Percentage_Summary.csv - Summary statistics\n",
    "\n",
    "TABLE STRUCTURE:\n",
    "‚Ä¢ Player Name\n",
    "‚Ä¢ Total Judge Score\n",
    "‚Ä¢ Judge Score %\n",
    "‚Ä¢ Estimated Fan Votes  \n",
    "‚Ä¢ Fan Vote %\n",
    "‚Ä¢ Total %\n",
    "‚Ä¢ Final row: TOTAL with sums\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nHOW TO USE FOR MCM PROBLEM C:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"\"\"\n",
    "1. Compare Judge Score % vs Fan Vote % for each player\n",
    "2. Identify controversial cases (high fan, low judge scores)\n",
    "3. Calculate Fan/Judge ratio to measure fan influence\n",
    "4. Use the data to model different voting systems:\n",
    "   - Rank-based system vs Percentage-based system\n",
    "   - How each system amplifies or diminishes fan influence\n",
    "5. Test your fan vote estimation model against known controversial cases\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nKEY FINDINGS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Calculate overall fan influence\n",
    "avg_judge_percent = data_without_total['Judge Score %'].mean()\n",
    "avg_fan_percent = data_without_total['Fan Vote %'].mean()\n",
    "print(f\"Average Judge Score % per player: {avg_judge_percent:.4f}%\")\n",
    "print(f\"Average Fan Vote % per player: {avg_fan_percent:.4f}%\")\n",
    "print(f\"Average Fan/Judge ratio: {avg_fan_percent/avg_judge_percent:.2f}\")\n",
    "\n",
    "# Count controversial cases (ratio > 2.0)\n",
    "controversial_count = len(data_without_total[data_without_total['Fan Vote %'] > 2 * data_without_total['Judge Score %']])\n",
    "print(f\"\\nPlayers with strong fan support (Fan % > 2√ó Judge %): {controversial_count} out of {len(data_without_total)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS READY FOR MCM PROBLEM C SUBMISSION!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f63609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel(\"merged_data_with_predictions.xlsx\")\n",
    "\n",
    "def clean(x):\n",
    "    \"\"\"Clean and normalize names\"\"\"\n",
    "    x = str(x).lower()\n",
    "    x = unicodedata.normalize(\"NFKD\", x)\n",
    "    return \"\".join(c for c in x if c.isalpha())\n",
    "\n",
    "df[\"name_clean\"] = df[\"celebrity_name\"].apply(clean)\n",
    "\n",
    "# Controversial contestants mapping\n",
    "name_map = {\n",
    "    2: \"Jerry Rice\",\n",
    "    4: \"Billy Ray Cyrus\",\n",
    "    11: \"Bristol Palin\",\n",
    "    27: \"Bobby Bones\"\n",
    "}\n",
    "\n",
    "# Method mapping for each season\n",
    "method_map = {\n",
    "    2: \"rank\",\n",
    "    4: \"percent\",\n",
    "    11: \"percent\",\n",
    "    27: \"percent\"\n",
    "}\n",
    "\n",
    "# Create clean name mapping for controversial contestants\n",
    "controversial = {s: clean(n) for s,n in name_map.items()}\n",
    "\n",
    "# Extract week numbers\n",
    "weeks = sorted({\n",
    "    int(c.replace(\"Week\",\"\").split(\"_\")[0])\n",
    "    for c in df.columns if \"Predicted_Fan_Votes\" in c\n",
    "})\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Process each controversial contestant\n",
    "for season, star in controversial.items():\n",
    "\n",
    "    season_df = df[df[\"season\"] == season].copy()\n",
    "    alive = set(season_df[\"name_clean\"])\n",
    "\n",
    "    for week in weeks:\n",
    "\n",
    "        fan_col = f\"Week{week}_Predicted_Fan_Votes\"\n",
    "        judge_cols = [c for c in season_df.columns if c.startswith(f\"week{week}_judge\")]\n",
    "\n",
    "        if fan_col not in season_df.columns or not judge_cols:\n",
    "            continue\n",
    "\n",
    "        alive_df = season_df[season_df[\"name_clean\"].isin(alive)].copy()\n",
    "        if len(alive_df) <= 1:\n",
    "            break\n",
    "\n",
    "        F = alive_df[fan_col]\n",
    "        J = alive_df[judge_cols].sum(axis=1)\n",
    "\n",
    "        mask = ~F.isna()\n",
    "        alive_df = alive_df[mask]\n",
    "        F = F[mask].values\n",
    "        J = J[mask].values\n",
    "\n",
    "        if len(alive_df) <= 1:\n",
    "            break\n",
    "\n",
    "        alive_df[\"judge_sum\"] = J\n",
    "        n = len(alive_df)\n",
    "\n",
    "        # ===== Ranking calculation =====\n",
    "        if method_map[season] == \"percent\":\n",
    "            # Percentage method: J/J.sum() + F/F.sum()\n",
    "            S = J/J.sum() + F/F.sum()\n",
    "            order = np.argsort(-S)\n",
    "        else:\n",
    "            # Rank method: rJ + rF\n",
    "            rJ = pd.Series(J).rank(ascending=False).values\n",
    "            rF = pd.Series(F).rank(ascending=False).values\n",
    "            S = rJ + rF\n",
    "            order = np.argsort(S)\n",
    "\n",
    "        ranks = np.empty(n)\n",
    "        ranks[order] = np.arange(1, n+1)\n",
    "        alive_df[\"rank\"] = ranks\n",
    "\n",
    "        sorted_df = alive_df.sort_values(\"rank\", ascending=False)\n",
    "        bottom1 = sorted_df.iloc[0]\n",
    "        bottom2 = sorted_df.iloc[1]\n",
    "\n",
    "        if star in alive_df[\"name_clean\"].values:\n",
    "\n",
    "            star_row = alive_df[alive_df[\"name_clean\"] == star].iloc[0]\n",
    "            star_rank = int(star_row[\"rank\"])\n",
    "            is_bottom2 = star_rank >= n - 1\n",
    "\n",
    "            should_eliminate = False\n",
    "\n",
    "            if is_bottom2 and bottom2[\"name_clean\"] == star:\n",
    "                should_eliminate = star_row[\"judge_sum\"] < bottom1[\"judge_sum\"]\n",
    "\n",
    "            rows.append({\n",
    "                \"season\": season,\n",
    "                \"week\": week,\n",
    "                \"contestant\": star_row[\"celebrity_name\"],\n",
    "                \"method\": method_map[season],\n",
    "                \"rank\": star_rank,\n",
    "                \"is_bottom2\": is_bottom2,\n",
    "                \"bottom1\": bottom1[\"celebrity_name\"] if is_bottom2 else None,\n",
    "                \"judge_contestant\": star_row[\"judge_sum\"] if is_bottom2 else None,\n",
    "                \"judge_bottom1\": bottom1[\"judge_sum\"] if is_bottom2 else None,\n",
    "                \"should_be_eliminated\": should_eliminate\n",
    "            })\n",
    "\n",
    "        # ===== Advance real elimination =====\n",
    "        real_out = season_df[season_df[fan_col].isna()]\n",
    "        if len(real_out) == 1:\n",
    "            alive.remove(clean(real_out.iloc[0][\"celebrity_name\"]))\n",
    "\n",
    "# ======================\n",
    "# Export results\n",
    "# ======================\n",
    "\n",
    "pd.DataFrame(rows).to_excel(\n",
    "    \"controversial_mixed_method_ranking_with_decision.xlsx\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Complete ranking table with theoretical elimination decisions generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e608a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import unicodedata\n",
    "\n",
    "# ======================\n",
    "# Read Data\n",
    "# ======================\n",
    "\n",
    "df = pd.read_excel(\"merged_data_with_predictions.xlsx\")\n",
    "\n",
    "# ======================\n",
    "# Name Cleaning\n",
    "# ======================\n",
    "\n",
    "def clean(x):\n",
    "    x = str(x).lower()\n",
    "    x = unicodedata.normalize(\"NFKD\", x)\n",
    "    return \"\".join(c for c in x if c.isalpha())\n",
    "\n",
    "df[\"name_clean\"] = df[\"celebrity_name\"].apply(clean)\n",
    "\n",
    "# ======================\n",
    "# Controversial Contestants and Method Selection\n",
    "# ======================\n",
    "\n",
    "name_map = {\n",
    "    2: \"Jerry Rice\",\n",
    "    4: \"Billy Ray Cyrus\", \n",
    "    11: \"Bristol Palin\",\n",
    "    27: \"Bobby Bones\"\n",
    "}\n",
    "\n",
    "method_map = {\n",
    "    2: \"rank\",\n",
    "    4: \"percent\", \n",
    "    11: \"percent\",\n",
    "    27: \"percent\"\n",
    "}\n",
    "\n",
    "controversial = {s: clean(n) for s, n in name_map.items()}\n",
    "\n",
    "# ======================\n",
    "# Extract Weeks\n",
    "# ======================\n",
    "\n",
    "weeks = sorted({\n",
    "    int(c.replace(\"Week\", \"\").split(\"_\")[0])\n",
    "    for c in df.columns if \"Predicted_Fan_Votes\" in c\n",
    "})\n",
    "\n",
    "# ======================\n",
    "# Store Results\n",
    "# ======================\n",
    "\n",
    "tracks = {}\n",
    "alive_counts = {}\n",
    "\n",
    "# ======================\n",
    "# Main Loop\n",
    "# ======================\n",
    "\n",
    "for season, star in controversial.items():\n",
    "\n",
    "    season_df = df[df[\"season\"] == season].copy()\n",
    "    alive = set(season_df[\"name_clean\"])\n",
    "\n",
    "    tracks[season] = []\n",
    "    alive_counts[season] = []\n",
    "\n",
    "    for w in weeks:\n",
    "\n",
    "        fan_col = f\"Week{w}_Predicted_Fan_Votes\"\n",
    "        judge_cols = [c for c in season_df.columns if c.startswith(f\"week{w}_judge\")]\n",
    "\n",
    "        if fan_col not in season_df.columns or not judge_cols:\n",
    "            continue\n",
    "\n",
    "        alive_df = season_df[season_df[\"name_clean\"].isin(alive)].copy()\n",
    "        if len(alive_df) <= 1:\n",
    "            break\n",
    "\n",
    "        F = alive_df[fan_col]\n",
    "        J = alive_df[judge_cols].sum(axis=1)\n",
    "\n",
    "        mask = ~F.isna()\n",
    "        alive_df = alive_df[mask]\n",
    "        F = F[mask].values\n",
    "        J = J[mask].values\n",
    "\n",
    "        if len(alive_df) <= 1:\n",
    "            break\n",
    "\n",
    "        n = len(alive_df)\n",
    "        alive_counts[season].append(n)\n",
    "\n",
    "        # ======================\n",
    "        # Calculate Rankings\n",
    "        # ======================\n",
    "\n",
    "        if method_map[season] == \"percent\":\n",
    "            S = J/J.sum() + F/F.sum()\n",
    "            order = np.argsort(-S)\n",
    "\n",
    "        else:  # rank method\n",
    "            rJ = pd.Series(J).rank(ascending=False).values\n",
    "            rF = pd.Series(F).rank(ascending=False).values\n",
    "            S = rJ + rF\n",
    "            order = np.argsort(S)\n",
    "\n",
    "        ranks = np.empty(n)\n",
    "        ranks[order] = np.arange(1, n+1)\n",
    "\n",
    "        # ======================\n",
    "        # Record Controversial Contestant\n",
    "        # ======================\n",
    "\n",
    "        if star in alive_df[\"name_clean\"].values:\n",
    "            idx = list(alive_df[\"name_clean\"]).index(star)\n",
    "            tracks[season].append(ranks[idx])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        # ======================\n",
    "        # Advance Real Elimination\n",
    "        # ======================\n",
    "\n",
    "        real_out = season_df[season_df[fan_col].isna()]\n",
    "        if len(real_out) == 1:\n",
    "            alive.remove(clean(real_out.iloc[0][\"celebrity_name\"]))\n",
    "\n",
    "# ======================\n",
    "# Plotting (Bottom 2 Highlight)\n",
    "# ======================\n",
    "\n",
    "plt.figure(figsize=(11, 6))\n",
    "\n",
    "for season, y in tracks.items():\n",
    "\n",
    "    name = name_map[season]\n",
    "    x = range(1, len(y)+1)\n",
    "\n",
    "    plt.plot(x, y, marker=\"o\", linewidth=2, label=name)\n",
    "\n",
    "    for i, rank in enumerate(y):\n",
    "        n = alive_counts[season][i]\n",
    "        bottom2_start = n - 1\n",
    "\n",
    "        # Red danger zone\n",
    "        plt.axhspan(bottom2_start, n,\n",
    "                    xmin=i/len(y), xmax=(i+1)/len(y),\n",
    "                    color=\"red\", alpha=0.18)\n",
    "\n",
    "        # Red dots\n",
    "        if rank >= bottom2_start:\n",
    "            plt.scatter(i+1, rank, s=90, color=\"red\", zorder=5)\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Rank (1 = Best)\")\n",
    "plt.title(\"Controversial Contestants ‚Äì Best-Fit Ranking with Bottom 2 Highlighted\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d40b93",
   "metadata": {},
   "source": [
    "3rd problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6ce57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1. Import libraries and data\n",
    "# =========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set plot style\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "raw = pd.read_csv(\"2026_MCM_Problem_C_Data.csv\")\n",
    "pred = pd.read_excel(\"merged_data_with_predictions.xlsx\")\n",
    "\n",
    "print(f\"Raw data shape: {raw.shape}\")\n",
    "print(f\"Prediction data shape: {pred.shape}\")\n",
    "\n",
    "# =========================\n",
    "# 2. Data cleaning and merging\n",
    "# =========================\n",
    "\n",
    "# Name cleaning function\n",
    "def clean_name(x):\n",
    "    \"\"\"Clean and normalize names\"\"\"\n",
    "    x = str(x).lower()\n",
    "    x = unicodedata.normalize(\"NFKD\", x)\n",
    "    return \"\".join(c for c in x if c.isalpha())\n",
    "\n",
    "print(\"\\nCleaning names...\")\n",
    "raw[\"name_clean\"] = raw[\"celebrity_name\"].apply(clean_name)\n",
    "pred[\"name_clean\"] = pred[\"celebrity_name\"].apply(clean_name)\n",
    "\n",
    "# Industry reclassification function\n",
    "def categorize_industry(industry):\n",
    "    \"\"\"Categorize industries into standardized groups\"\"\"\n",
    "    if pd.isna(industry):\n",
    "        return \"Other\"\n",
    "    \n",
    "    industry = str(industry).lower()\n",
    "    \n",
    "    # Actor category\n",
    "    actor_keywords = [\"actor\", \"actress\", \"actor/actress\"]\n",
    "    if any(keyword in industry for keyword in actor_keywords):\n",
    "        return \"Actor/Actress\"\n",
    "    \n",
    "    # Athlete category\n",
    "    athlete_keywords = [\"athlete\", \"sports\", \"racing\"]\n",
    "    if any(keyword in industry for keyword in athlete_keywords):\n",
    "        return \"Athlete\"\n",
    "    \n",
    "    # Singer/idol category\n",
    "    music_keywords = [\"singer\", \"rapper\", \"musician\"]\n",
    "    if any(keyword in industry for keyword in music_keywords):\n",
    "        return \"Singer/Musician\"\n",
    "    \n",
    "    # Model category\n",
    "    if \"model\" in industry:\n",
    "        return \"Model\"\n",
    "    \n",
    "    # TV personality\n",
    "    tv_keywords = [\"tv personality\", \"reality\", \"social media\"]\n",
    "    if any(keyword in industry for keyword in tv_keywords):\n",
    "        return \"TV Personality\"\n",
    "    \n",
    "    # Other\n",
    "    return \"Other\"\n",
    "\n",
    "print(\"Categorizing occupations...\")\n",
    "raw[\"occupation_category\"] = raw[\"celebrity_industry\"].apply(categorize_industry)\n",
    "\n",
    "# Check data columns\n",
    "print(\"\\nRaw data columns:\")\n",
    "print(raw.columns.tolist())\n",
    "\n",
    "# Find age column\n",
    "age_col = None\n",
    "for col in raw.columns:\n",
    "    if 'age' in col.lower():\n",
    "        age_col = col\n",
    "        break\n",
    "\n",
    "print(f\"\\nAge column found: {age_col}\")\n",
    "\n",
    "# Merge data\n",
    "print(\"Merging data...\")\n",
    "if age_col:\n",
    "    industry_map = raw[[\"name_clean\", \"occupation_category\", age_col]].drop_duplicates()\n",
    "    industry_map = industry_map.rename(columns={age_col: \"age\"})\n",
    "else:\n",
    "    industry_map = raw[[\"name_clean\", \"occupation_category\"]].drop_duplicates()\n",
    "    industry_map[\"age\"] = np.nan\n",
    "\n",
    "df = pred.merge(industry_map, on=\"name_clean\", how=\"left\")\n",
    "print(f\"Merged data shape: {df.shape}\")\n",
    "\n",
    "# =========================\n",
    "# 3. Extract weekly data\n",
    "# =========================\n",
    "\n",
    "print(\"\\nExtracting weekly data...\")\n",
    "week_cols = [c for c in df.columns if \"Predicted_Fan_Votes\" in c]\n",
    "weeks = []\n",
    "\n",
    "for col in week_cols:\n",
    "    try:\n",
    "        week_num = int(col.replace(\"Week\", \"\").split(\"_\")[0])\n",
    "        weeks.append(week_num)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "weeks = sorted(set(weeks))\n",
    "print(f\"Weeks found: {weeks}\")\n",
    "\n",
    "# =========================\n",
    "# 4. Calculate weekly rankings\n",
    "# =========================\n",
    "\n",
    "print(\"\\nCalculating weekly rankings...\")\n",
    "all_data = []\n",
    "\n",
    "for w in weeks:\n",
    "    fan_col = f\"Week{w}_Predicted_Fan_Votes\"\n",
    "    \n",
    "    if fan_col not in df.columns:\n",
    "        continue\n",
    "    \n",
    "    # Find judge score columns\n",
    "    judge_patterns = [f\"week{w}_judge\", f\"Week{w}_Judge\"]\n",
    "    judge_cols = []\n",
    "    \n",
    "    for pattern in judge_patterns:\n",
    "        judge_cols = [c for c in df.columns if c.startswith(pattern)]\n",
    "        if judge_cols:\n",
    "            break\n",
    "    \n",
    "    if not judge_cols:\n",
    "        continue\n",
    "    \n",
    "    # Filter rows with data\n",
    "    week_data = df[~df[fan_col].isna()].copy()\n",
    "    \n",
    "    if len(week_data) < 2:\n",
    "        continue\n",
    "    \n",
    "    # Calculate totals and rankings\n",
    "    week_data[\"judge_total\"] = week_data[judge_cols].sum(axis=1)\n",
    "    week_data[\"fan_votes\"] = week_data[fan_col]\n",
    "    \n",
    "    week_data[\"judge_rank\"] = week_data[\"judge_total\"].rank(ascending=False)\n",
    "    week_data[\"fan_rank\"] = week_data[\"fan_votes\"].rank(ascending=False)\n",
    "    \n",
    "    week_data[\"week\"] = w\n",
    "    \n",
    "    # Select required columns\n",
    "    keep_cols = [\"occupation_category\", \"age\", \"judge_rank\", \"fan_rank\", \"week\", \"celebrity_name\"]\n",
    "    all_data.append(week_data[keep_cols])\n",
    "\n",
    "# Check if data exists\n",
    "if not all_data:\n",
    "    print(\"Error: No valid data found!\")\n",
    "    exit()\n",
    "\n",
    "# Combine all data\n",
    "all_rankings = pd.concat(all_data, ignore_index=True)\n",
    "print(f\"\\nTotal data points: {len(all_rankings)}\")\n",
    "\n",
    "# =========================\n",
    "# 5. Analyze occupation performance\n",
    "# =========================\n",
    "\n",
    "print(\"\\nAnalyzing occupation performance...\")\n",
    "occupation_stats = all_rankings.groupby(\"occupation_category\").agg({\n",
    "    \"judge_rank\": [\"mean\", \"count\"],\n",
    "    \"fan_rank\": [\"mean\", \"count\"]\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Average Ranking Statistics by Occupation\")\n",
    "print(\"=\"*60)\n",
    "print(occupation_stats)\n",
    "\n",
    "# =========================\n",
    "# 6. Analyze age performance\n",
    "# =========================\n",
    "\n",
    "print(\"\\nAnalyzing age performance...\")\n",
    "all_rankings[\"age_numeric\"] = pd.to_numeric(all_rankings[\"age\"], errors='coerce')\n",
    "age_data = all_rankings[~all_rankings[\"age_numeric\"].isna()].copy()\n",
    "\n",
    "if len(age_data) > 0:\n",
    "    # Create age groups\n",
    "    age_data[\"age_group\"] = pd.cut(age_data[\"age_numeric\"], \n",
    "                                  bins=[0, 20, 30, 40, 50, 60, 100],\n",
    "                                  labels=[\"<20\", \"20-29\", \"30-39\", \"40-49\", \"50-59\", \"60+\"])\n",
    "    \n",
    "    age_stats = age_data.groupby(\"age_group\").agg({\n",
    "        \"judge_rank\": [\"mean\", \"count\"],\n",
    "        \"fan_rank\": [\"mean\", \"count\"]\n",
    "    }).round(2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Performance Statistics by Age Group\")\n",
    "    print(\"=\"*60)\n",
    "    print(age_stats)\n",
    "    \n",
    "    has_age_data = True\n",
    "else:\n",
    "    print(\"No valid age data\")\n",
    "    has_age_data = False\n",
    "\n",
    "# =========================\n",
    "# 7. Create visualizations\n",
    "# =========================\n",
    "\n",
    "print(\"\\nCreating visualizations...\")\n",
    "\n",
    "# Prepare data\n",
    "occupations = occupation_stats.index.tolist()\n",
    "judge_means = occupation_stats[(\"judge_rank\", \"mean\")]\n",
    "fan_means = occupation_stats[(\"fan_rank\", \"mean\")]\n",
    "\n",
    "# Create charts\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle(\"DWTS Performance Analysis by Occupation and Age\", fontsize=16, fontweight='bold')\n",
    "\n",
    "# Subplot 1: Occupation performance comparison\n",
    "ax1 = axes[0, 0]\n",
    "x = np.arange(len(occupations))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, judge_means, width, label='Judge', color='blue', alpha=0.7)\n",
    "bars2 = ax1.bar(x + width/2, fan_means, width, label='Fan', color='red', alpha=0.7)\n",
    "\n",
    "ax1.set_xlabel('Occupation')\n",
    "ax1.set_ylabel('Average Rank (Lower = Better)')\n",
    "ax1.set_title('Judge vs Fan Rankings by Occupation')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(occupations, rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add values\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Subplot 2: Judge rankings\n",
    "ax2 = axes[0, 1]\n",
    "colors = plt.cm.tab20c(np.linspace(0, 1, len(occupations)))\n",
    "bars_judge = ax2.bar(occupations, judge_means, color=colors)\n",
    "ax2.set_xlabel('Occupation')\n",
    "ax2.set_ylabel('Average Judge Rank')\n",
    "ax2.set_title('Judge Rankings by Occupation')\n",
    "ax2.set_xticklabels(occupations, rotation=45, ha='right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "for bar in bars_judge:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.1f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Subplot 3: Fan rankings\n",
    "ax3 = axes[1, 0]\n",
    "bars_fan = ax3.bar(occupations, fan_means, color=colors)\n",
    "ax3.set_xlabel('Occupation')\n",
    "ax3.set_ylabel('Average Fan Rank')\n",
    "ax3.set_title('Fan Rankings by Occupation')\n",
    "ax3.set_xticklabels(occupations, rotation=45, ha='right')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "for bar in bars_fan:\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.1f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Subplot 4: Ranking differences\n",
    "ax4 = axes[1, 1]\n",
    "rank_diff = fan_means - judge_means\n",
    "colors_diff = ['green' if d > 0 else 'orange' for d in rank_diff]\n",
    "bars_diff = ax4.bar(occupations, rank_diff, color=colors_diff)\n",
    "ax4.set_xlabel('Occupation')\n",
    "ax4.set_ylabel('Rank Difference (Fan - Judge)')\n",
    "ax4.set_title('Preference Difference\\nPositive = Fans Prefer More')\n",
    "ax4.set_xticklabels(occupations, rotation=45, ha='right')\n",
    "ax4.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "for bar in bars_diff:\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., \n",
    "            height + (0.1 if height > 0 else -0.4),\n",
    "            f'{height:+.1f}', ha='center', \n",
    "            va='bottom' if height > 0 else 'top', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('occupation_analysis.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Create age charts if age data exists\n",
    "if has_age_data:\n",
    "    fig2, axes2 = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    fig2.suptitle(\"Age Performance Analysis\", fontsize=16)\n",
    "    \n",
    "    age_groups = age_stats.index.tolist()\n",
    "    judge_age = age_stats[(\"judge_rank\", \"mean\")]\n",
    "    fan_age = age_stats[(\"fan_rank\", \"mean\")]\n",
    "    \n",
    "    # Age vs judge ranking\n",
    "    ax5 = axes2[0]\n",
    "    ax5.plot(age_groups, judge_age, marker='o', linewidth=2, label='Judge')\n",
    "    ax5.set_xlabel('Age Group')\n",
    "    ax5.set_ylabel('Average Judge Rank')\n",
    "    ax5.set_title('Age vs Judge Performance')\n",
    "    ax5.legend()\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Age vs fan ranking\n",
    "    ax6 = axes2[1]\n",
    "    ax6.plot(age_groups, fan_age, marker='s', linewidth=2, color='red', label='Fan')\n",
    "    ax6.set_xlabel('Age Group')\n",
    "    ax6.set_ylabel('Average Fan Rank')\n",
    "    ax6.set_title('Age vs Fan Popularity')\n",
    "    ax6.legend()\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('age_analysis.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# =========================\n",
    "# 8. Results summary\n",
    "# =========================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Key Findings Summary\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Best occupations\n",
    "best_judge = occupation_stats[(\"judge_rank\", \"mean\")].idxmin()\n",
    "best_fan = occupation_stats[(\"fan_rank\", \"mean\")].idxmin()\n",
    "print(f\"1. Highest judge-rated occupation: {best_judge}\")\n",
    "print(f\"2. Highest fan-voted occupation: {best_fan}\")\n",
    "\n",
    "# Preference differences\n",
    "pref_diff = {}\n",
    "for occ in occupations:\n",
    "    judge_val = occupation_stats.loc[occ, (\"judge_rank\", \"mean\")]\n",
    "    fan_val = occupation_stats.loc[occ, (\"fan_rank\", \"mean\")]\n",
    "    pref_diff[occ] = fan_val - judge_val\n",
    "\n",
    "judge_favored = min(pref_diff, key=pref_diff.get)\n",
    "fan_favored = max(pref_diff, key=pref_diff.get)\n",
    "print(f\"3. Judge's most preferred occupation: {judge_favored} (difference: {pref_diff[judge_favored]:.1f})\")\n",
    "print(f\"4. Fans' most preferred occupation: {fan_favored} (difference: {pref_diff[fan_favored]:.1f})\")\n",
    "\n",
    "if has_age_data:\n",
    "    best_judge_age = age_stats[(\"judge_rank\", \"mean\")].idxmin()\n",
    "    best_fan_age = age_stats[(\"fan_rank\", \"mean\")].idxmin()\n",
    "    print(f\"5. Highest judge-rated age group: {best_judge_age}\")\n",
    "    print(f\"6. Highest fan-voted age group: {best_fan_age}\")\n",
    "\n",
    "print(\"\\nDetailed occupation rankings:\")\n",
    "print(\"-\"*40)\n",
    "for occ in occupations:\n",
    "    judge_val = occupation_stats.loc[occ, (\"judge_rank\", \"mean\")]\n",
    "    fan_val = occupation_stats.loc[occ, (\"fan_rank\", \"mean\")]\n",
    "    diff = fan_val - judge_val\n",
    "    count = int(occupation_stats.loc[occ, (\"judge_rank\", \"count\")])\n",
    "    pref = \"Fans prefer more\" if diff > 0 else \"Judges prefer more\"\n",
    "    print(f\"{occ:20s} | Judge: {judge_val:5.1f} | Fan: {fan_val:5.1f} | Diff: {diff:+.1f} | {pref} | Sample: {count}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Analysis complete! Charts saved as occupation_analysis.png\")\n",
    "if has_age_data:\n",
    "    print(\"Age charts saved as age_analysis.png\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3cd17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load raw data and predictions\n",
    "raw = pd.read_csv(\"2026_MCM_Problem_C_Data.csv\")\n",
    "pred = pd.read_excel(\"merged_data_with_predictions.xlsx\")\n",
    "\n",
    "def clean_name(x):\n",
    "    \"\"\"Clean and normalize celebrity names\"\"\"\n",
    "    x = str(x).lower()\n",
    "    x = unicodedata.normalize(\"NFKD\", x)\n",
    "    return \"\".join(c for c in x if c.isalpha())\n",
    "\n",
    "# Apply name cleaning to both datasets\n",
    "raw[\"name_clean\"] = raw[\"celebrity_name\"].apply(clean_name)\n",
    "pred[\"name_clean\"] = pred[\"celebrity_name\"].apply(clean_name)\n",
    "\n",
    "def categorize(ind):\n",
    "    \"\"\"Categorize industries into standardized groups\"\"\"\n",
    "    if pd.isna(ind): return \"Other\"\n",
    "    ind = str(ind).lower()\n",
    "    if \"actor\" in ind: return \"Actor\"\n",
    "    if \"athlete\" in ind or \"sport\" in ind: return \"Athlete\"\n",
    "    if \"singer\" in ind or \"musician\" in ind: return \"Music\"\n",
    "    if \"tv\" in ind or \"reality\" in ind: return \"TV\"\n",
    "    return \"Other\"\n",
    "\n",
    "# Apply industry categorization\n",
    "raw[\"occupation_category\"] = raw[\"celebrity_industry\"].apply(categorize)\n",
    "\n",
    "# Find age column\n",
    "age_col = [c for c in raw.columns if \"age\" in c.lower()][0]\n",
    "\n",
    "# Prepare basic info dataframe\n",
    "info = raw[[\"name_clean\",\"occupation_category\",age_col]].drop_duplicates()\n",
    "info = info.rename(columns={age_col:\"age\"})\n",
    "\n",
    "# Merge dataframes\n",
    "df = pred.merge(info, on=\"name_clean\", how=\"left\")\n",
    "\n",
    "# Identify judge and fan vote columns\n",
    "judge_cols = [c for c in df.columns if \"Judge\" in c or \"judge\" in c]\n",
    "fan_cols = [c for c in df.columns if \"Predicted_Fan_Votes\" in c]\n",
    "\n",
    "# Calculate totals\n",
    "df[\"judge_total\"] = df[judge_cols].sum(axis=1)\n",
    "df[\"fan_total\"] = df[fan_cols].sum(axis=1)\n",
    "\n",
    "# Prepare analysis dataset\n",
    "analysis = df[[\"name_clean\",\"occupation_category\",\"age\",\"judge_total\",\"fan_total\"]].dropna()\n",
    "\n",
    "# Create industry mapping codes\n",
    "industry_map = {k:i+1 for i,k in enumerate(analysis[\"occupation_category\"].unique())}\n",
    "analysis[\"industry_code\"] = analysis[\"occupation_category\"].map(industry_map)\n",
    "\n",
    "# Clean age data\n",
    "analysis[\"age\"] = pd.to_numeric(analysis[\"age\"], errors=\"coerce\")\n",
    "analysis = analysis.dropna()\n",
    "\n",
    "def topsis(X, w):\n",
    "    \"\"\"TOPSIS method for multi-criteria decision making\"\"\"\n",
    "    # Normalize the matrix\n",
    "    R = X / np.sqrt((X**2).sum(axis=0))\n",
    "    # Calculate weighted normalized matrix\n",
    "    V = R * w\n",
    "    # Determine ideal and worst solutions\n",
    "    ideal = V.max(axis=0)\n",
    "    worst = V.min(axis=0)\n",
    "    # Calculate distances\n",
    "    Dp = np.sqrt(((V - ideal)**2).sum(axis=1))\n",
    "    Dn = np.sqrt(((V - worst)**2).sum(axis=1))\n",
    "    # Calculate relative closeness\n",
    "    return Dn / (Dp + Dn)\n",
    "\n",
    "# Prepare feature matrix\n",
    "X = analysis[[\"age\",\"industry_code\",\"judge_total\",\"fan_total\"]].values\n",
    "\n",
    "# Weight configurations\n",
    "# Judge-dominated weights\n",
    "w_judge = np.array([0.15,0.15,0.55,0.15])\n",
    "\n",
    "# Fan-dominated weights  \n",
    "w_fan = np.array([0.10,0.20,0.15,0.55])\n",
    "\n",
    "# Apply TOPSIS with different weight schemes\n",
    "analysis[\"Judge_TOPSIS\"] = topsis(X, w_judge)\n",
    "analysis[\"Fan_TOPSIS\"] = topsis(X, w_fan)\n",
    "\n",
    "# Calculate rankings\n",
    "analysis[\"Judge_rank\"] = analysis[\"Judge_TOPSIS\"].rank(ascending=False)\n",
    "analysis[\"Fan_rank\"] = analysis[\"Fan_TOPSIS\"].rank(ascending=False)\n",
    "\n",
    "# Calculate ranking differences\n",
    "analysis[\"Rank_gap\"] = analysis[\"Fan_rank\"] - analysis[\"Judge_rank\"]\n",
    "\n",
    "# Analyze industry bias\n",
    "industry_bias = analysis.groupby(\"occupation_category\").agg({\n",
    "    \"Judge_rank\":\"mean\",\n",
    "    \"Fan_rank\":\"mean\",\n",
    "    \"name_clean\":\"count\"\n",
    "}).rename(columns={\"name_clean\":\"n\"})\n",
    "\n",
    "industry_bias[\"Preference_Index\"] = industry_bias[\"Fan_rank\"] - industry_bias[\"Judge_rank\"]\n",
    "\n",
    "# Print results\n",
    "print(\"\\n====== Industry Preference Index ======\\n\")\n",
    "print(industry_bias.sort_values(\"Preference_Index\", ascending=False))\n",
    "\n",
    "# Calculate bias strength metrics\n",
    "bias_strength = np.mean(np.abs(analysis[\"Rank_gap\"]))\n",
    "print(\"\\nOverall mechanism bias strength:\", round(bias_strength,2))\n",
    "print(\"Maximum individual deviation:\", analysis[\"Rank_gap\"].abs().max())\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(analysis[\"Judge_rank\"], analysis[\"Fan_rank\"], alpha=0.7)\n",
    "plt.plot([1,len(analysis)], [1,len(analysis)], linestyle=\"--\")\n",
    "plt.xlabel(\"Judge-based Ranking\")\n",
    "plt.ylabel(\"Fan-based Ranking\")\n",
    "plt.title(\"Ranking Discrepancy Between Evaluation Mechanisms\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8e2e3d",
   "metadata": {},
   "source": [
    "4th problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efec336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data (assuming files are in the same folder)\n",
    "df_raw = pd.read_excel('merged_data_with_predictions.xlsx')\n",
    "\n",
    "# Focus on a specific season (e.g., Season 32)\n",
    "SEASON = 32\n",
    "df_season = df_raw[df_raw['season'] == SEASON].copy()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Extract judge score columns (week*_judge*_score)\n",
    "# --------------------------------------------------\n",
    "judge_cols = [c for c in df_season.columns if 'week' in c and 'judge' in c]\n",
    "\n",
    "# Create (contestant, week) ‚Üí average judge score mapping\n",
    "records = []\n",
    "\n",
    "for _, row in df_season.iterrows():\n",
    "    name = row['celebrity_name']\n",
    "    for col in judge_cols:\n",
    "        if not pd.isna(row[col]):\n",
    "            # Parse week number\n",
    "            week = int(col.split('_')[0].replace('week', ''))\n",
    "            records.append({\n",
    "                'celebrity_name': name,\n",
    "                'week': week,\n",
    "                'pJ_raw': row[col]\n",
    "            })\n",
    "\n",
    "df_judge_long = pd.DataFrame(records)\n",
    "\n",
    "# Average multiple judges for the same week\n",
    "df_judge_week = (\n",
    "    df_judge_long\n",
    "    .groupby(['celebrity_name', 'week'], as_index=False)\n",
    "    .agg(pJ=('pJ_raw', 'mean'))\n",
    ")\n",
    "\n",
    "# Get fan voting data\n",
    "fan_col = f'Season{SEASON}_Avg_Fan_Pct'\n",
    "df_fan = df_season[['celebrity_name', fan_col]].rename(columns={fan_col: 'pF'})\n",
    "\n",
    "# Merge datasets\n",
    "df = df_judge_week.merge(df_fan, on='celebrity_name', how='left')\n",
    "\n",
    "# Calculate contestant statistics (mean and standard deviation)\n",
    "judge_stats = (\n",
    "    df\n",
    "    .groupby('celebrity_name')\n",
    "    .agg(\n",
    "        mu_J=('pJ', 'mean'),\n",
    "        sigma_J=('pJ', 'std')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "judge_stats['rank_J'] = judge_stats['mu_J'].rank(ascending=False, method='min')\n",
    "\n",
    "# Set weights and stability protection factor\n",
    "wJ, wF = 0.5, 0.5\n",
    "alpha = 0.2  # Increase alpha to enhance stability factor's impact on S_star\n",
    "eps = 1e-6\n",
    "\n",
    "# Merge judge statistics\n",
    "df = df.merge(judge_stats, on='celebrity_name', how='left')\n",
    "\n",
    "# Calculate stability protection factor B\n",
    "df['B'] = alpha * df['mu_J'] / (df['sigma_J'] + eps)\n",
    "\n",
    "# Calculate comprehensive score S_star\n",
    "df['S_star'] = (\n",
    "    wJ * df['pJ'] +\n",
    "    wF * df['pF'] +\n",
    "    df['B']\n",
    ")\n",
    "\n",
    "# Set elimination criteria: elimination score (e.g., contestants with S_star below threshold)\n",
    "threshold = 2.5  # Assuming contestants with S_star < 2.5 are eliminated\n",
    "\n",
    "# Mark eliminated contestants\n",
    "df['eliminated'] = df['S_star'] < threshold\n",
    "\n",
    "# Data for remaining contestants\n",
    "df_remaining = df[~df['eliminated']]\n",
    "\n",
    "# Calculate weekly elimination stability: only consider contestants still in competition\n",
    "elimination = (\n",
    "    df_remaining\n",
    "    .groupby('week')\n",
    "    .agg(S_star_mean=('S_star', 'mean'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Output elimination scores (by week)\n",
    "print(\"Weekly Elimination Stability (Mean Score):\")\n",
    "print(elimination[['week', 'S_star_mean']])\n",
    "\n",
    "# Final stage score adjustment\n",
    "K = 3\n",
    "lambda_penalty = 0.05  # Reduce lambda_penalty value to avoid over-penalization\n",
    "\n",
    "# Get final week\n",
    "final_week = df['week'].max()\n",
    "df_final = df[df['week'] == final_week].copy()\n",
    "\n",
    "# Calculate final score (for champion ranking adjustment)\n",
    "df_final['final_score'] = np.where(\n",
    "    df_final['rank_J'] <= K,\n",
    "    df_final['S_star'],\n",
    "    df_final['S_star'] - lambda_penalty * (df_final['rank_J'] - K)\n",
    ")\n",
    "\n",
    "# Compare original system vs new system scores\n",
    "df_final['S_original'] = wJ * df_final['pJ'] + wF * df_final['pF']  # Original score\n",
    "df_final['S_A'] = df_final['S_star']  # System A\n",
    "df_final['S_B'] = df_final['final_score']  # System B\n",
    "\n",
    "# Print final scores and rankings to confirm differences\n",
    "print(\"Final Scores and Rank J:\")\n",
    "print(df_final[['celebrity_name', 'rank_J', 'S_star', 'final_score']])\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 1Ô∏è‚É£ Compare champion judge rankings\n",
    "champ = df_final.iloc[0]\n",
    "\n",
    "# Create champion judge ranking comparison chart\n",
    "plt.bar(\n",
    "    ['Original', 'System A', 'System B'],\n",
    "    [champ['rank_J']] * 3\n",
    ")\n",
    "plt.ylabel('Judge Rank of Champion')\n",
    "plt.title('Champion Professional Ranking Comparison')\n",
    "plt.show()\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2Ô∏è‚É£ Original system vs new system score distribution\n",
    "plt.hist(df_final['S_original'], bins=10, alpha=0.6, label='Original')\n",
    "plt.hist(df_final['S_B'], bins=10, alpha=0.6, label='New System')\n",
    "plt.legend()\n",
    "plt.title('Final Score Distribution Comparison')\n",
    "plt.show()\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3Ô∏è‚É£ Single-week elimination stability comparison\n",
    "plt.plot(elimination['week'], elimination['S_star_mean'], marker='o')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Mean Eliminated Score')\n",
    "plt.title('Weekly Elimination Stability')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
